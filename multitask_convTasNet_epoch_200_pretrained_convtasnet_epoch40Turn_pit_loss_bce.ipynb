{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLvCxOrrKzgy"
      },
      "source": [
        "Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7Gy-iEXDU0W",
        "outputId": "b4dedc3a-e977-4c89-f425-f4077a2d6a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.15.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (1.1.5)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain) (2025.6.15)\n",
            "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyperpyyaml, speechbrain\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed hyperpyyaml-1.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 speechbrain-1.0.3\n",
            "Collecting mir_eval\n",
            "  Downloading mir_eval-0.8.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from mir_eval) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mir_eval) (1.15.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mir_eval) (4.4.2)\n",
            "Downloading mir_eval-0.8.2-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mir_eval\n",
            "Successfully installed mir_eval-0.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade speechbrain\n",
        "!pip install mir_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRvbNfp-K63d"
      },
      "source": [
        "Generate data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyRYdH_E1vqc",
        "outputId": "379a9199-81b0-4608-c74c-dd49f5a22e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "drive.mount('/content/drive')\n",
        "zip_path = '/content/drive/MyDrive/Project/dataset_2500.zip'\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "  zip_ref.extractall('./dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rOGCKEMhw9Q"
      },
      "source": [
        "Hparams yaml File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3gEuzUMh0PF"
      },
      "outputs": [],
      "source": [
        "\n",
        "!mkdir /content/dataset/metadata\n",
        "!mkdir /content/dataset/metadata/test\n",
        "!mkdir /content/dataset/metadata/train\n",
        "!mkdir /content/dataset/metadata/validate\n",
        "!mv /content/dataset/test/metadata.csv /content/dataset/metadata/test/\n",
        "!mv /content/dataset/train/metadata.csv /content/dataset/metadata/train/\n",
        "!mv /content/dataset/validate/metadata.csv /content/dataset/metadata/validate/\n",
        "# !rm -rf './hparams'\n",
        "!mkdir './hparams'\n",
        "!cp '/content/drive/MyDrive/Project/sepformer.yml' './hparams/'\n",
        "!cp -r '/content/drive/MyDrive/Project/pretrained_convtasnet' './'\n",
        "# !cp '/content/drive/MyDrive/Project/conVasNet.yml' './hparams/'\n",
        "!cp '/content/drive/MyDrive/Project/conVasNet_p.yml' './hparams/'\n",
        "!cp '/content/drive/MyDrive/Project/preprocess_dynamic_mixing.py' './'\n",
        "!cp '/content/drive/MyDrive/Project/dynamic_mixing.py' './'\n",
        "!cp '/content/drive/MyDrive/Project/prepare_data.py' './'\n",
        "# !cp -r '/content/drive/MyDrive/Project/results' './'\n",
        "!cp -r '/content/drive/MyDrive/Project/results_176' './'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUfwK5NkrdkV"
      },
      "source": [
        "Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUKQYBJrbz8"
      },
      "outputs": [],
      "source": [
        "def dataio_prep(hparams):\n",
        "    \"\"\"Creates data processing pipeline\"\"\"\n",
        "\n",
        "    # 1. Define datasets\n",
        "    train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"train_data\"],\n",
        "        replacements={\"data_root\": hparams[\"data_folder\"]},\n",
        "    )\n",
        "\n",
        "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"valid_data\"],\n",
        "        replacements={\"data_root\": hparams[\"data_folder\"]},\n",
        "    )\n",
        "\n",
        "    test_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"test_data\"],\n",
        "        replacements={\"data_root\": hparams[\"data_folder\"]},\n",
        "    )\n",
        "\n",
        "    datasets = [train_data, valid_data, test_data]\n",
        "\n",
        "    # 2. Provide audio pipelines\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"mix_wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"mix_sig\")\n",
        "    def audio_pipeline_mix(mix_wav):\n",
        "        mix_sig = sb.dataio.dataio.read_audio(mix_wav)\n",
        "        return mix_sig\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"s1_wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"s1_sig\")\n",
        "    def audio_pipeline_s1(s1_wav):\n",
        "        s1_sig = sb.dataio.dataio.read_audio(s1_wav)\n",
        "        return s1_sig\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"s2_wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"s2_sig\")\n",
        "    def audio_pipeline_s2(s2_wav):\n",
        "        s2_sig = sb.dataio.dataio.read_audio(s2_wav)\n",
        "        return s2_sig\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"languages\")\n",
        "    @sb.utils.data_pipeline.provides(\"lang_id\")\n",
        "    def lang_id_pipeline(lang_str):\n",
        "      lang_id = lang_str.split(',')\n",
        "      yield encode_languages(lang_id)\n",
        "\n",
        "    @sb.utils.data_pipeline.takes(\"length\")\n",
        "    @sb.utils.data_pipeline.provides(\"lens\")\n",
        "    def length_pipeline(length):\n",
        "      return length\n",
        "\n",
        "    if hparams[\"num_spks\"] == 3:\n",
        "\n",
        "        @sb.utils.data_pipeline.takes(\"s3_wav\")\n",
        "        @sb.utils.data_pipeline.provides(\"s3_sig\")\n",
        "        def audio_pipeline_s3(s3_wav):\n",
        "            s3_sig = sb.dataio.dataio.read_audio(s3_wav)\n",
        "            return s3_sig\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_mix)\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s1)\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s2)\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, lang_id_pipeline)\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, length_pipeline)\n",
        "    if hparams[\"num_spks\"] == 3:\n",
        "      sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s3)\n",
        "      sb.dataio.dataset.set_output_keys(datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"s3_sig\", \"lang_id\", \"lens\"])\n",
        "    else:\n",
        "      sb.dataio.dataset.set_output_keys(datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"lang_id\", \"lens\"])\n",
        "\n",
        "    return train_data, valid_data, test_data\n",
        "\n",
        "def encode_languages(language_list):\n",
        "  label = []\n",
        "  for lang in language_list:\n",
        "    vec = torch.zeros(16)\n",
        "    label_encoder = hparams[\"label_encoder\"]\n",
        "    label_encoder.expect_len(16) #new Line Added\n",
        "    label_encoder.update_from_iterable(hparams[\"all_langs\"])\n",
        "    idx = label_encoder.encode_label(lang)\n",
        "    vec[idx] = 1.0\n",
        "    label.append(vec)\n",
        "  label = torch.stack(label)\n",
        "  # print(f\"Label = {label}\")\n",
        "  return label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MTNQ4PCLC6S"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GhUXxc4Y9o3"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from  speechbrain.nnet.losses import PitWrapper\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "import speechbrain as sb\n",
        "import speechbrain.nnet.schedulers as schedulers\n",
        "from speechbrain.utils.distributed import run_on_main\n",
        "from speechbrain.utils.logger import get_logger\n",
        "from speechbrain.utils.train_logger import FileTrainLogger\n",
        "from speechbrain.nnet.losses import bce_loss, PitWrapper\n",
        "from speechbrain.utils.metric_stats import ClassificationStats\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MultiTask(sb.Brain):\n",
        "  def on_stage_start(self, stage, epoch):\n",
        "    # if stage != sb.Stage.TRAIN:\n",
        "      # self.error_metrics = self.hparams.error_stats()\n",
        "    self.train_epoch_acc = 0\n",
        "    self.test_epoch_acc_p = 0\n",
        "    self.test_epoch_acc = 0\n",
        "    self.val_epoc_acc_s = 0\n",
        "    self.val_epoc_acc_p = 0\n",
        "    self.all_embeddings = []\n",
        "    self.all_labels = []\n",
        "    self.print_num =0;\n",
        "    if stage == sb.Stage.TRAIN:\n",
        "      if epoch < 40:\n",
        "        self.hparams.delta_lang_loss = 1.0\n",
        "        self.hparams.delta_separate_loss = 0.0\n",
        "        for name in ['encoder', 'masknet', 'decoder']:\n",
        "            for param in getattr(self.modules, name).parameters():\n",
        "                param.requires_grad = False\n",
        "      elif epoch == 40:\n",
        "        self.hparams.delta_lang_loss = 0.95\n",
        "        self.hparams.delta_separate_loss = 0.05\n",
        "        logger.info(\"Unfreezing Convtasnet\")\n",
        "        for name in ['encoder', 'masknet', 'decoder']:\n",
        "            for param in getattr(self.modules, name).parameters():\n",
        "                param.requires_grad = True\n",
        "        unfrozen_params = filter(lambda p: p.requires_grad, self.modules.parameters())\n",
        "        self.optimizer = torch.optim.Adam(unfrozen_params, lr=self.hparams.lr, weight_decay=0)\n",
        "\n",
        "    self.uttid = [0]\n",
        "    if stage in [sb.Stage.VALID, sb.Stage.TEST]:\n",
        "      self.stats = ClassificationStats()\n",
        "    self.file_logger = FileTrainLogger(\"/content/results/print_statements\")\n",
        "    self.pit_bce = PitWrapper(nn.BCEWithLogitsLoss(reduction='none'))\n",
        "\n",
        "\n",
        "  def compute_forward(self, mix, targets, lang_id,  stage):\n",
        "    mix, mix_lens = mix\n",
        "    mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n",
        "    targets = torch.stack([t.data for t in targets], dim=-1).to(self.device)\n",
        "    if stage == sb.Stage.TRAIN:\n",
        "      with torch.no_grad():\n",
        "        if self.hparams.use_speedperturb:\n",
        "            mix, targets = self.add_speed_perturb(targets, mix_lens)\n",
        "\n",
        "            mix = targets.sum(-1)\n",
        "\n",
        "        if self.hparams.use_wavedrop:\n",
        "            mix = self.hparams.drop_chunk(mix, mix_lens)\n",
        "            mix = self.hparams.drop_freq(mix)\n",
        "\n",
        "        if self.hparams.limit_training_signal_len:\n",
        "            mix, targets = self.cut_signals(mix, targets)\n",
        "\n",
        "    #ConvTasNet\n",
        "    with torch.amp.autocast(device_type='cuda', enabled=False):\n",
        "      mixe = self.hparams.Encoder(mix)\n",
        "      est_mask = self.hparams.MaskNet(mixe)\n",
        "    mixe = torch.stack([mixe] * self.hparams.num_spks)\n",
        "    sep_h = mixe * est_mask\n",
        "    est_source = torch.cat([self.hparams.Decoder(sep_h[i]).unsqueeze(-1) for i in range(self.hparams.num_spks)], dim=-1)\n",
        "    T_origin = mix.size(1)\n",
        "    T_est = est_source.size(1)\n",
        "    if T_origin > T_est:\n",
        "        est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n",
        "    else:\n",
        "        est_source = est_source[:, :T_origin, :]\n",
        "\n",
        "    #ECAPA-TDNN\n",
        "    batch_size, seq_len, num_spks = est_source.shape\n",
        "    est_source_combined = est_source.view(batch_size * num_spks, seq_len)\n",
        "    feats = self.modules.compute_features(est_source_combined)\n",
        "    mix_len_combined = mix_lens.repeat(num_spks)\n",
        "    feats = self.modules.mean_var_norm(feats, mix_len_combined)\n",
        "    embeddings = self.modules.embedding_model(feats, mix_len_combined)\n",
        "    outputs = self.modules.classifier(embeddings)\n",
        "    pred_lang_id = outputs.view(batch_size, num_spks, -1)\n",
        "    return est_source, targets, lang_id, mix_lens, pred_lang_id, embeddings\n",
        "\n",
        "  def lang_accuracy(self, lang_id, probs):\n",
        "    # print(f\"lang_id_size = {lang_id.shape}, probs = {probs.shape}\")\n",
        "    lang_id = lang_id.squeeze(0)\n",
        "    probs = probs.squeeze(0)\n",
        "    # print(f\"lang_id_size = {lang_id.shape}, probs = {probs.shape}\")\n",
        "    acc1_s = (torch.sum(probs[0,0] * lang_id[0]) + torch.sum(probs[0,1] * lang_id[1])) /2\n",
        "    acc2_s = (torch.sum(probs[0,0] * lang_id[1]) + torch.sum(probs[0,1] * lang_id[0])) /2\n",
        "\n",
        "    preds = torch.argmax(probs.unsqueeze(0), dim=-1)     # shape: [1, 2]\n",
        "    targets = torch.argmax(lang_id, dim=-1)\n",
        "\n",
        "    acc1_p = int(preds[0,0] == targets[0]) + int(preds[0,1] == targets[1])\n",
        "    acc2_p = int(preds[0,0] == targets[1]) + int(preds[0,1] == targets[0])\n",
        "    return max(acc1_s, acc2_s).item(), max(acc1_p, acc2_p)/2\n",
        "\n",
        "  def compute_objectives(self, predictions, targets, lang_id, lens, pred_lang_id,stage, uttid):\n",
        "    # print(\"predictions:\",predictions, \"targets = \", targets)\n",
        "\n",
        "    separate_loss = self.hparams.loss(targets, predictions)\n",
        "    lang_id = lang_id.data.float().to(pred_lang_id.device)\n",
        "    predictions = pred_lang_id.transpose(1,2)\n",
        "    targets = lang_id.transpose(1,2)\n",
        "    lang_loss, perms = self.pit_bce(predictions,targets)\n",
        "    separate_loss = separate_loss.mean()\n",
        "    lang_loss = lang_loss.mean()\n",
        "\n",
        "    loss = self.hparams.delta_lang_loss * lang_loss + self.hparams.delta_separate_loss*separate_loss\n",
        "    self.file_logger.log_stats(stats_meta = {\"Target size = \":targets.size(), \"Predictions size =\": predictions.size(), \"lang_id = \": lang_id, \"pred_lang_id = \": pred_lang_id, \"stage =\":stage, \"Separate loss =\": separate_loss, \"lang_loss = \":lang_loss,\"Loss =\":loss, \"Perms =\": perms}, verbose=False)\n",
        "    if stage == sb.Stage.VALID or stage == sb.Stage.TEST:\n",
        "      probs = torch.sigmoid(pred_lang_id)\n",
        "      preds = torch.argmax(probs, dim=-1)       # Shape: [1, 2]\n",
        "      target_language = torch.argmax(lang_id, dim=-1)\n",
        "      for b in range(preds.shape[0]):\n",
        "          for spk in range(preds.shape[1]):\n",
        "              self.stats.append(\n",
        "                  ids=[f\"utt{b}_spk{spk}\"],\n",
        "                  predictions=[self.hparams.all_langs[preds[b, spk].item()]],\n",
        "                  targets=[self.hparams.all_langs[target_language[b, spk].item()]],\n",
        "                  categories=self.hparams.all_langs\n",
        "              )\n",
        "    if stage == sb.Stage.TEST:\n",
        "      probs = torch.sigmoid(pred_lang_id)\n",
        "      lang_acc_s,lang_acc_p = self.lang_accuracy(lang_id,probs)\n",
        "      self.test_epoch_acc = (self.test_epoch_acc*(self.uttid[0]-1) + lang_acc_s)*(1/self.uttid[0])\n",
        "      self.test_epoch_acc_p = (self.test_epoch_acc_p*(self.uttid[0]-1) + lang_acc_p)*(1/self.uttid[0])\n",
        "\n",
        "    return loss,lang_loss,separate_loss\n",
        "\n",
        "  def fit_batch(self,batch):\n",
        "    mixture = batch.mix_sig\n",
        "    targets = [batch.s1_sig, batch.s2_sig]\n",
        "    lang_id = batch.lang_id\n",
        "    self.uttid[0] = self.uttid[0] + 1\n",
        "    with torch.amp.autocast(device_type='cuda'):\n",
        "      est_source, targets, lang_id, lens, pred_lang_id,embeddings = self.compute_forward(\n",
        "        mixture, targets, lang_id, sb.Stage.TRAIN\n",
        "      )\n",
        "      loss,lang_loss,separate_loss = self.compute_objectives(\n",
        "        est_source, targets, lang_id, lens, pred_lang_id,sb.Stage.TRAIN, self.uttid\n",
        "      )\n",
        "      # self.lang_loss_epoch = lang_loss.mean()\n",
        "      # self.sep_loss_epoch = separate_loss.mean()\n",
        "      if self.hparams.threshold_byloss:\n",
        "        th = self.hparams.threshold\n",
        "        loss = loss[loss > th]\n",
        "        if loss.nelement() > 0:\n",
        "            loss = loss.mean()\n",
        "      else:\n",
        "        loss = loss.mean()\n",
        "\n",
        "    if loss.nelement() > 0 and loss < self.hparams.loss_upper_lim:\n",
        "      self.scaler.scale(loss).backward()\n",
        "      if self.hparams.clip_grad_norm >= 0:\n",
        "        self.scaler.unscale_(self.optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "          self.modules.parameters(),\n",
        "          self.hparams.clip_grad_norm,\n",
        "        )\n",
        "      self.scaler.step(self.optimizer)\n",
        "      self.scaler.update()\n",
        "    else:\n",
        "      self.nonfinite_count += 1\n",
        "      logger.info(\n",
        "        \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n",
        "          self.nonfinite_count\n",
        "        )\n",
        "      )\n",
        "      loss.data = torch.tensor(0.0).to(self.device)\n",
        "    self.optimizer.zero_grad()\n",
        "\n",
        "    return loss.detach().cpu()\n",
        "\n",
        "\n",
        "  def evaluate_batch(self, batch, stage):\n",
        "\n",
        "    \"\"\"Computations needed for validation/test batches\"\"\"\n",
        "    snt_id = batch.id\n",
        "    mixture = batch.mix_sig\n",
        "    targets = [batch.s1_sig, batch.s2_sig]\n",
        "    lang_id = batch.lang_id\n",
        "    self.uttid[0] = self.uttid[0] + 1\n",
        "    if self.hparams.num_spks == 3:\n",
        "      targets.append(batch.s3_sig)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # compute_forward returns multiple values for multi-task\n",
        "      est_source, targets, lang_id, lens, pred_lang_id, embeddings = self.compute_forward(\n",
        "        mixture, targets, lang_id,  stage\n",
        "      )\n",
        "      # compute_objectives combines both tasks into a single loss\n",
        "      loss,lang_loss,separate_loss = self.compute_objectives(\n",
        "        est_source, targets, lang_id, lens, pred_lang_id, stage, self.uttid\n",
        "      )\n",
        "    if stage == sb.Stage.TEST and self.hparams.save_audio:\n",
        "\n",
        "      if hasattr(self.hparams, \"n_audio_to_save\"):\n",
        "        if self.hparams.n_audio_to_save > 0:\n",
        "          self.save_audio(snt_id[0], mixture, targets, est_source)\n",
        "          self.hparams.n_audio_to_save += -1\n",
        "      else:\n",
        "        self.save_audio(snt_id[0], mixture, targets, est_source)\n",
        "\n",
        "\n",
        "    return loss.mean().detach()\n",
        "\n",
        "  def on_stage_end(self, stage, stage_loss, epoch):\n",
        "    stage_stats = {\"final_loss\": stage_loss}\n",
        "    log_buffer = io.StringIO()\n",
        "    if stage == sb.Stage.TRAIN:\n",
        "      self.train_stats = stage_stats\n",
        "      # train_loss.append(self.train_stats[\"final_loss\"])\n",
        "      file_loc = f\"/content/results_{epoch}\"\n",
        "      if(epoch%2 ==0):\n",
        "        os.rename(r\"/content/results\", file_loc)\n",
        "        !cp -r $file_loc '/content/drive/MyDrive/Project'\n",
        "        if(epoch > 2):\n",
        "          prev_file_loc = f\"/content/drive/MyDrive/Project/results_{epoch-2}\"\n",
        "          !rm -rf $prev_file_loc\n",
        "          logger.info(f\"Removed file {prev_file_loc}\")\n",
        "        os.rename(file_loc,r\"/content/results\")\n",
        "        logger.info(\"Saved file succesfully\")\n",
        "    if stage == sb.Stage.TEST or stage == sb.Stage.VALID:\n",
        "      summary = self.stats.summarize()\n",
        "      self.stats.write_stats(log_buffer)  # Write stats into buffer instead of stdout\n",
        "      log_text = log_buffer.getvalue()\n",
        "    if stage == sb.Stage.VALID:\n",
        "      # Learning rate annealing\n",
        "      # epoch_list.append(epoch)\n",
        "      if isinstance(self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau):\n",
        "        current_lr, next_lr = self.hparams.lr_scheduler(\n",
        "            [self.optimizer], epoch, stage_loss\n",
        "        )\n",
        "        schedulers.update_learning_rate(self.optimizer, next_lr)\n",
        "      else:\n",
        "        # if we do not use the reducelronplateau, we do not change the lr\n",
        "        current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n",
        "\n",
        "      self.hparams.train_logger.log_stats(\n",
        "          stats_meta={\"epoch\": epoch, \"lr\": current_lr, \"Stats\":log_text},\n",
        "          train_stats=self.train_stats,\n",
        "          valid_stats={\"final_loss\": stage_loss, \"Overall Accuracy:\" : summary[\"accuracy\"], \"Classwise Accuracy: \":summary[\"classwise_accuracy\"]},\n",
        "          verbose = False\n",
        "      )\n",
        "      print(f\"Epoch : {epoch}, Current_lr: {current_lr}, Train Loss: {self.train_stats['final_loss']}, Validation Loss: {stage_loss}, Validation Accuracy: {summary['accuracy']}\")\n",
        "      # val_accuracy_s.append(self.val_epoc_acc_s)\n",
        "      # val_accuracy_p.append(self.val_epoc_acc_p)\n",
        "\n",
        "      # valid_loss.append(stage_stats[\"final_loss\"])\n",
        "\n",
        "      self.checkpointer.save_and_keep_only(\n",
        "          meta={\"final_loss\": stage_stats[\"final_loss\"]}, min_keys=[\"final_loss\"]\n",
        "      )\n",
        "    elif stage == sb.Stage.TEST:\n",
        "      self.hparams.train_logger.log_stats(\n",
        "\n",
        "        stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current, \"Accuracy soft\": self.test_epoch_acc, \"Accuracy Partial\" : self.test_epoch_acc_p},\n",
        "        test_stats=stage_stats,\n",
        "      )\n",
        "    log_buffer.close()\n",
        "\n",
        "  def add_speed_perturb(self, targets, targ_lens):\n",
        "    \"\"\"Adds speed perturbation and random_shift to the input signals\"\"\"\n",
        "\n",
        "    min_len = -1\n",
        "    recombine = False\n",
        "\n",
        "    if self.hparams.use_speedperturb or self.hparams.use_rand_shift:\n",
        "      # Performing speed change (independently on each source)\n",
        "      new_targets = []\n",
        "      recombine = True\n",
        "\n",
        "      for i in range(targets.shape[-1]):\n",
        "        new_target = self.hparams.speed_perturb(targets[:, :, i])\n",
        "        new_targets.append(new_target)\n",
        "        if i == 0:\n",
        "          min_len = new_target.shape[-1]\n",
        "        else:\n",
        "          if new_target.shape[-1] < min_len:\n",
        "            min_len = new_target.shape[-1]\n",
        "\n",
        "      if self.hparams.use_rand_shift:\n",
        "        # Performing random_shift (independently on each source)\n",
        "        recombine = True\n",
        "        for i in range(targets.shape[-1]):\n",
        "            rand_shift = torch.randint(\n",
        "                self.hparams.min_shift, self.hparams.max_shift, (1,)\n",
        "            )\n",
        "            new_targets[i] = new_targets[i].to(self.device)\n",
        "            new_targets[i] = torch.roll(\n",
        "                new_targets[i], shifts=(rand_shift[0],), dims=1\n",
        "            )\n",
        "\n",
        "        # Re-combination\n",
        "        if recombine:\n",
        "            if self.hparams.use_speedperturb:\n",
        "                targets = torch.zeros(\n",
        "                    targets.shape[0],\n",
        "                    min_len,\n",
        "                    targets.shape[-1],\n",
        "                    device=targets.device,\n",
        "                    dtype=torch.float,\n",
        "                )\n",
        "            for i, new_target in enumerate(new_targets):\n",
        "                targets[:, :, i] = new_targets[i][:, 0:min_len]\n",
        "\n",
        "    mix = targets.sum(-1)\n",
        "    return mix, targets\n",
        "\n",
        "  def cut_signals(self, mixture, targets):\n",
        "      \"\"\"This function selects a random segment of a given length within the mixture.\n",
        "      The corresponding targets are selected accordingly\"\"\"\n",
        "      randstart = torch.randint(\n",
        "          0,\n",
        "          1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n",
        "          (1,),\n",
        "      ).item()\n",
        "      targets = targets[\n",
        "          :, randstart : randstart + self.hparams.training_signal_len, :\n",
        "      ]\n",
        "      mixture = mixture[\n",
        "          :, randstart : randstart + self.hparams.training_signal_len\n",
        "      ]\n",
        "      return mixture, targets\n",
        "\n",
        "\n",
        "  def reset_layer_recursively(self, layer):\n",
        "      \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n",
        "      if hasattr(layer, \"reset_parameters\"):\n",
        "          layer.reset_parameters()\n",
        "      for child_layer in layer.modules():\n",
        "          if layer != child_layer:\n",
        "              self.reset_layer_recursively(child_layer)\n",
        "\n",
        "  def save_results(self, test_data):\n",
        "\n",
        "    \"\"\"This script computes the SDR and SI-SNR metrics and saves\n",
        "    them into a csv file\"\"\"\n",
        "\n",
        "    # This package is required for SDR computation\n",
        "    from mir_eval.separation import bss_eval_sources\n",
        "\n",
        "    # Create folders where to store audio\n",
        "    save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n",
        "\n",
        "    # Variable init\n",
        "    all_sdrs = []\n",
        "    all_sdrs_i = []\n",
        "    all_sisnrs = []\n",
        "    all_sisnrs_i = []\n",
        "    csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n",
        "\n",
        "    test_loader = sb.dataio.dataloader.make_dataloader(\n",
        "      test_data, **self.hparams.dataloader_opts\n",
        "    )\n",
        "\n",
        "    with open(save_file, \"w\", newline=\"\", encoding=\"utf-8\") as results_csv:\n",
        "      writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n",
        "      writer.writeheader()\n",
        "\n",
        "      # Loop over all test sentence\n",
        "      with tqdm(test_loader, dynamic_ncols=True) as t:\n",
        "          for i, batch in enumerate(t):\n",
        "            # Apply Separation\n",
        "            mixture, mix_len = batch.mix_sig\n",
        "            snt_id = batch.id\n",
        "            targets = [batch.s1_sig, batch.s2_sig]\n",
        "            lang_id = batch.lang_id\n",
        "            # lens = batch.lens\n",
        "            self.uttid[0] = self.uttid[0] + 1\n",
        "            if self.hparams.num_spks == 3:\n",
        "              targets.append(batch.s3_sig)\n",
        "\n",
        "            with torch.no_grad():\n",
        "              predictions, targets, lang_id, lens, pred_lang_id, embeddings = self.compute_forward(\n",
        "                  batch.mix_sig, targets, lang_id,  sb.Stage.TEST\n",
        "              )\n",
        "\n",
        "            # Compute SI-SNR\n",
        "            total_loss,lang_loss,sisnr = self.compute_objectives(predictions, targets,lang_id,lens,pred_lang_id, sb.Stage.TEST, self.uttid)\n",
        "\n",
        "            # Compute SI-SNR improvement\n",
        "            mixture_signal = torch.stack(\n",
        "              [mixture] * self.hparams.num_spks, dim=-1\n",
        "            )\n",
        "            mixture_signal = mixture_signal.to(targets.device)\n",
        "            total_loss,lang_loss,sisnr_baseline = self.compute_objectives(\n",
        "              mixture_signal, targets, lang_id, lens, pred_lang_id, sb.Stage.TEST, self.uttid\n",
        "            )\n",
        "            sisnr_i = sisnr - sisnr_baseline\n",
        "\n",
        "            # Compute SDR\n",
        "            ref = targets[0].t().cpu().numpy()\n",
        "            est = predictions[0].t().detach().cpu().numpy()\n",
        "            if np.any(np.all(ref == 0, axis=1)):\n",
        "              print(f\"Skipping uttid: {self.uttid[0]} as all the targets are zero\")\n",
        "              continue\n",
        "            sdr, _, _, _ = bss_eval_sources(ref,est)\n",
        "\n",
        "            sdr_baseline, _, _, _ = bss_eval_sources(ref,est)\n",
        "\n",
        "\n",
        "            sdr_i = sdr.mean() - sdr_baseline.mean()\n",
        "\n",
        "            # Saving on a csv file\n",
        "            row = {\n",
        "              \"snt_id\": snt_id[0],\n",
        "              \"sdr\": sdr.mean(),\n",
        "              \"sdr_i\": sdr_i,\n",
        "              \"si-snr\": -sisnr.item(),\n",
        "              \"si-snr_i\": -sisnr_i.item(),\n",
        "            }\n",
        "            writer.writerow(row)\n",
        "\n",
        "            # Metric Accumulation\n",
        "            all_sdrs.append(sdr.mean())\n",
        "            all_sdrs_i.append(sdr_i.mean())\n",
        "            all_sisnrs.append(-sisnr.item())\n",
        "            all_sisnrs_i.append(-sisnr_i.item())\n",
        "\n",
        "          row = {\n",
        "            \"snt_id\": \"avg\",\n",
        "            \"sdr\": np.array(all_sdrs).mean(),\n",
        "            \"sdr_i\": np.array(all_sdrs_i).mean(),\n",
        "            \"si-snr\": np.array(all_sisnrs).mean(),\n",
        "            \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n",
        "          }\n",
        "          writer.writerow(row)\n",
        "\n",
        "    logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n",
        "    logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
        "    logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n",
        "    logger.info(\"Mean SDRi is {}\".format(np.array(all_sisnrs_i).mean()))\n",
        "\n",
        "  def save_audio(self, snt_id, mixture, targets, predictions):\n",
        "    \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n",
        "\n",
        "    # Create output folder\n",
        "    save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n",
        "    if not os.path.exists(save_path):\n",
        "      os.mkdir(save_path)\n",
        "\n",
        "    for ns in range(self.hparams.num_spks):\n",
        "      # Estimated source\n",
        "      signal = predictions[0, :, ns]\n",
        "      signal = signal / signal.abs().max()\n",
        "      save_file = os.path.join(\n",
        "        save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n",
        "      )\n",
        "      torchaudio.save(\n",
        "        save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
        "      )\n",
        "\n",
        "      # Original source\n",
        "      signal = targets[0, :, ns]\n",
        "      signal = signal / signal.abs().max()\n",
        "      save_file = os.path.join(\n",
        "        save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n",
        "      )\n",
        "      torchaudio.save(\n",
        "        save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
        "      )\n",
        "\n",
        "    # Mixture\n",
        "    signal = mixture[0][0, :]\n",
        "    signal = signal / signal.abs().max()\n",
        "    save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n",
        "    torchaudio.save(\n",
        "      save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n",
        "    )\n",
        "  # def get_language(path):\n",
        "  #   mixture = sb.dataio.dataio.read_audio(torchaudio.load())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoJv4IAnLFmI"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "INi7eq9HqIzm",
        "outputId": "33fe48fc-28ac-474e-97ae-25eb5d59b74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.seed - Setting seed to 1234\n",
            "speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
            "speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/convtasnet/1234\n",
            "Creating a csv file for a custom dataset\n",
            "__main__ - Train sampling rate:16000\n",
            "speechbrain.core - Info: precision arg from hparam file is used\n",
            "speechbrain.core - Info: noprogressbar arg from hparam file is used\n",
            "speechbrain.core - Gradscaler enabled: `False`\n",
            "speechbrain.core - Using training precision: `--precision=fp32`\n",
            "speechbrain.core - Using evaluation precision: `--eval_precision=fp32`\n",
            "speechbrain.core - MultiTask Model Statistics:\n",
            "* Total Number of Trainable Parameters: 27.8M\n",
            "* Total Number of Parameters: 27.8M\n",
            "* Trainable Parameters represent 100.0000% of the total size.\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/convtasnet/1234/save/CKPT+2025-06-26+03-28-21+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 14/1250 [00:03<04:54,  4.20it/s, train_loss=-8.37]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-33-186703528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m separator.fit(\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mseparator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speechbrain/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epoch_counter, train_set, valid_set, progressbar, train_loader_kwargs, valid_loader_kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \u001b[0;31m# Iterate epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1575\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1576\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speechbrain/core.py\u001b[0m in \u001b[0;36m_fit_train\u001b[0;34m(self, train_set, epoch, enable)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0msteps_since_ckpt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m                 self.avg_train_loss = self.update_average(\n\u001b[1;32m   1402\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_train_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-32-2564256840.py\u001b[0m in \u001b[0;36mfit_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muttid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muttid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m       est_source, targets, lang_id, lens, pred_lang_id,embeddings = self.compute_forward(\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mmixture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m       )\n",
            "\u001b[0;32m/tmp/ipython-input-32-2564256840.py\u001b[0m in \u001b[0;36mcompute_forward\u001b[0;34m(self, mix, targets, lang_id, stage)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0mmixe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mmixe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmixe\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_spks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0msep_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixe\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mest_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speechbrain/lobes/models/conv_tasnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mixture_w)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck_conv1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal_conv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_conv1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speechbrain/nnet/containers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speechbrain/lobes/models/conv_tasnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \"\"\"\n\u001b[1;32m    376\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speechbrain/nnet/containers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speechbrain/nnet/containers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speechbrain/nnet/CNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mwx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n\u001b[0;32m--> 370\u001b[0;31m         return F.conv1d(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Load hyperparameters file with command-line overrides\n",
        "import os\n",
        "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "args = [\"/content/hparams/conVasNet_p.yml\"]\n",
        "hparams_file, run_opts, overrides = sb.parse_arguments(args)\n",
        "\n",
        "\n",
        "epochs = 200\n",
        "with open(hparams_file, encoding=\"utf-8\") as fin:\n",
        "  hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "# Initialize ddp (useful only for multi-GPU DDP training)\n",
        "sb.utils.distributed.ddp_init_group(run_opts)\n",
        "\n",
        "# Logger info\n",
        "logger = get_logger(__name__)\n",
        "\n",
        "# Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "  experiment_directory=hparams[\"output_folder\"],\n",
        "  hyperparams_to_save=hparams_file,\n",
        "  overrides=overrides,\n",
        ")\n",
        "\n",
        "# Update precision to bf16 if the device is CPU and precision is fp16\n",
        "if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
        "  hparams[\"precision\"] = \"bf16\"\n",
        "\n",
        "# Check if wsj0_tr is set with dynamic mixing\n",
        "if hparams[\"dynamic_mixing\"] and not os.path.exists(hparams[\"base_folder_dm\"]):\n",
        "  raise ValueError(\"Please, specify a valid base_folder_dm folder when using dynamic mixing\")\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/')\n",
        "\n",
        "# Data preparation\n",
        "from prepare_data import prepare_wsjmix  # noqa\n",
        "\n",
        "run_on_main(\n",
        "    prepare_wsjmix,\n",
        "    kwargs={\n",
        "        \"datapath\": hparams[\"data_folder\"],\n",
        "        \"savepath\": hparams[\"save_folder\"],\n",
        "        \"n_spks\": hparams[\"num_spks\"],\n",
        "        \"skip_prep\": hparams[\"skip_prep\"],\n",
        "        \"fs\": hparams[\"sample_rate\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Create dataset objects\n",
        "if hparams[\"dynamic_mixing\"]:\n",
        "    from dynamic_mixing import dynamic_mix_data_prep\n",
        "\n",
        "    # if the base_folder for dm is not processed, preprocess them\n",
        "    if \"processed\" not in hparams[\"base_folder_dm\"]:\n",
        "        # if the processed folder already exists we just use it otherwise we do the preprocessing\n",
        "        if not os.path.exists(\n",
        "            os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
        "        ):\n",
        "            from preprocess_dynamic_mixing import resample_folder\n",
        "\n",
        "            print(\"Resampling the base folder\")\n",
        "            run_on_main(\n",
        "                resample_folder,\n",
        "                kwargs={\n",
        "                    \"input_folder\": hparams[\"base_folder_dm\"],\n",
        "                    \"output_folder\": os.path.normpath(\n",
        "                        hparams[\"base_folder_dm\"]\n",
        "                    )\n",
        "                    + \"_processed\",\n",
        "                    \"fs\": hparams[\"sample_rate\"],\n",
        "                    \"regex\": \"**/*.wav\",\n",
        "                },\n",
        "            )\n",
        "            # adjust the base_folder_dm path\n",
        "            hparams[\"base_folder_dm\"] = (\n",
        "                os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
        "            )\n",
        "        else:\n",
        "            print(\n",
        "                \"Using the existing processed folder on the same directory as base_folder_dm\"\n",
        "            )\n",
        "            hparams[\"base_folder_dm\"] = (\n",
        "                os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
        "            )\n",
        "\n",
        "    # Collecting the hparams for dynamic batching\n",
        "    dm_hparams = {\n",
        "        \"train_data\": hparams[\"train_data\"],\n",
        "        \"data_folder\": hparams[\"data_folder\"],\n",
        "        \"base_folder_dm\": hparams[\"base_folder_dm\"],\n",
        "        \"sample_rate\": hparams[\"sample_rate\"],\n",
        "        \"num_spks\": hparams[\"num_spks\"],\n",
        "        \"training_signal_len\": hparams[\"training_signal_len\"],\n",
        "        \"dataloader_opts\": hparams[\"dataloader_opts\"],\n",
        "    }\n",
        "    train_data = dynamic_mix_data_prep(dm_hparams)\n",
        "    _, valid_data, test_data = dataio_prep(hparams)\n",
        "else:\n",
        "    train_data, valid_data, test_data = dataio_prep(hparams)\n",
        "\n",
        "trainfile_test,sr = torchaudio.load(\"/content/dataset/train/mix/Indian_eng_as_9000.wav\")\n",
        "\n",
        "logger.info(f\"Train sampling rate:{sr}\")\n",
        "\n",
        "# Load pretrained model if pretrained_separator is present in the yaml\n",
        "# if \"pretrained_separator\" in hparams:\n",
        "#     run_on_main(hparams[\"pretrained_separator\"].collect_files, kwargs={\"default_source\": \"speechbrain/sepformer-wsj02mix\"})\n",
        "#     hparams[\"pretrained_separator\"].load_collected()\n",
        "\n",
        "# Brain class initialization\n",
        "separator = MultiTask(\n",
        "    modules=hparams[\"modules\"],\n",
        "    opt_class=hparams[\"optimizer\"],\n",
        "    hparams=hparams,\n",
        "    run_opts=run_opts,\n",
        "    checkpointer=hparams[\"checkpointer\"],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # re-initialize the parameters if we don't use a pretrained model\n",
        "# if \"pretrained_separator\" not in hparams:\n",
        "#   for module in separator.modules.values():\n",
        "#       separator.reset_layer_recursively(module)\n",
        "# else:\n",
        "#   logger.info(f\"Loading pretrained weights:{separator}\")\n",
        "#   pretrain = hparams[\"pretrained_separator\"]\n",
        "#   pretrain.collect_files()\n",
        "#   pretrain.load_collected()\n",
        "\n",
        "\n",
        "separator.fit(\n",
        "    separator.hparams.epoch_counter,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
        "    valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPKbPnBVVCVP"
      },
      "source": [
        "Graph loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "62Q9ZRCgB3Cu",
        "outputId": "e1cdc896-9c12-4349-e44f-2eca4e9b9971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.222, 0.222, 0.222, 0.222, 0.223, 0.222, 0.222, 0.222, 0.221, 0.222, 0.223, 0.222, 0.222, 0.223, 0.221, 0.222, 0.222, 0.222, 0.223, 0.222, 0.222, 0.222, 0.222, 0.222, 0.222, 0.222, 0.222, 0.222, 0.223, 0.222, 0.221, 0.222, 0.221, 0.222, 0.221, 0.221, 0.222, 0.142, 0.0355, -0.0373, -0.0883, -0.143, -0.183, -0.214, -0.242, -0.269, -0.292, -0.307, -0.328, -0.349, -0.36, -0.373, -0.389, -0.403, -0.411, -0.42, -0.429, -0.443, -0.451, -0.457, -0.474, -0.479, -0.487, -0.494, -0.504, -0.499, -0.51, -0.521, -0.526, -0.535, -0.537, -0.539, -0.55, -0.55, -0.565, -0.567, -0.571, -0.571, -0.572, -0.584, -0.581, -0.59, -0.595, -0.594, -0.599, -0.612, -0.624, -0.644, -0.648, -0.65, -0.654, -0.658, -0.661, -0.664, -0.661, -0.674, -0.68, -0.672, -0.677, -0.683, -0.674, -0.677, -0.681, -0.684, -0.687, -0.679, -0.68, -0.682, -0.684, -0.678, -0.679, -0.681, -0.678, -0.679, -0.68, -0.679, -0.68, -0.68, -0.68, -0.68, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.681, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682, -0.682]\n",
            "[0.242, 0.238, 0.242, 0.246, 0.235, 0.238, 0.236, 0.241, 0.249, 0.256, 0.246, 0.235, 0.234, 0.235, 0.234, 0.242, 0.235, 0.238, 0.236, 0.241, 0.233, 0.233, 0.233, 0.237, 0.235, 0.235, 0.235, 0.233, 0.249, 0.239, 0.237, 0.233, 0.238, 0.236, 0.235, 0.237, 0.239, 0.0702, 0.0328, 0.0618, -0.0427, -0.0538, -0.0381, -0.0628, -0.0698, -0.0768, -0.0782, -0.0649, -0.0985, -0.0735, -0.037, -0.0487, -0.0767, -0.0684, -0.0429, -0.0931, -0.0948, -0.0863, -0.0698, -0.0918, -0.0784, -0.0885, -0.0875, -0.0966, -0.098, -0.0821, -0.0869, -0.0865, -0.0719, -0.0924, -0.101, -0.0767, -0.092, -0.111, -0.105, -0.111, -0.0904, -0.104, -0.108, -0.101, -0.106, -0.094, -0.102, -0.0962, -0.0946, -0.101, -0.0979, -0.103, -0.102, -0.102, -0.108, -0.108, -0.107, -0.105, -0.108, -0.105, -0.106, -0.106, -0.106, -0.106, -0.118, -0.118, -0.117, -0.116, -0.115, -0.121, -0.119, -0.119, -0.118, -0.116, -0.115, -0.115, -0.113, -0.113, -0.112, -0.112, -0.112, -0.112, -0.112, -0.111, -0.111, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112, -0.112]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAkBRJREFUeJzs3Xl4VNX9x/HPZBICAcISA4QkElQUUESFggoRKAEEtciAC9gqlrpUUQLVqi0CbqUVFyhqrbVuvwoqIdpqEQVMJCqCiruItgVJQtiFAAESJvf3x80kmWRmMpPZJ+/X8+SZybln7pw7OU3Jx3O+12IYhiEAAAAAAAAghOLCPQAAAAAAAAC0PIRSAAAAAAAACDlCKQAAAAAAAIQcoRQAAAAAAABCjlAKAAAAAAAAIUcoBQAAAAAAgJAjlAIAAAAAAEDIEUoBAAAAAAAg5AilAAAAAAAAEHKEUgAAoMV67rnnZLFY9PHHH4d7KM3iGP/WrVuD9h5bt26VxWLRc889F7T3AAAALROhFAAACBpHaOLu68MPPwz3ECPa1KlT3X52K1euDPfwnBQWFspisSgvLy/cQwEAAFEiPtwDAAAAse/ee+9Vz549G7WfcsopYRhNdElMTNTTTz/dqL1///4aNWqUrrzySiUmJoZhZAAAAP4hlAIAAEE3duxYDRw4MNzDiErx8fH6+c9/7va41WoN4WgAAAACh+17AAAg7Bx1ix566CE9+uij6tGjh9q0aaNhw4bpq6++atT/nXfeUXZ2ttq2bauOHTtq/Pjx2rRpU6N+paWlmjZtmrp3767ExET17NlTv/71r1VZWenU79ixY5o1a5ZSU1PVtm1bTZgwQbt37/Y45oceekgWi0U//PBDo2N33XWXWrVqpR9//FGS9P3332vixInq1q2bWrdurYyMDF155ZU6cOCALx9TI65qSmVlZeniiy/We++9p0GDBql169Y66aST9MILLzi9dt++fbrtttvUr18/tWvXTsnJyRo7dqw+//xzv8bUlP/973+67LLL1LlzZyUlJencc8/Vv//970b9Fi9erNNPP11JSUnq1KmTBg4cqCVLltQeP3jwoHJzc5WVlaXExER16dJFo0aN0saNG53Os379el144YXq0KGDkpKSNGzYML3//vtOfbw9FwAACCxWSgEAgKA7cOCA9uzZ49RmsViUkpLi1PbCCy/o4MGDuvnmm3X06FEtWrRIP/3pT/Xll1+qa9eukqTVq1dr7NixOumkkzRv3jwdOXJEixcv1pAhQ7Rx40ZlZWVJkrZv365BgwZp//79uv7669W7d2+VlpYqLy9PFRUVatWqVe373nLLLerUqZPmzp2rrVu3auHChZo+fbpefvllt9d0+eWX67e//a1eeeUV3X777U7HXnnlFY0ePVqdOnVSZWWlxowZo2PHjumWW25Rt27dVFpaqjfeeEP79+9Xhw4dmvz8Gn52CQkJHl/3n//8R5MmTdK0adN0zTXX6JlnntHUqVM1YMAAnX766ZLMcOi1117TZZddpp49e2rnzp3661//qmHDhumbb75R9+7dmxyXr3bu3Knzzz9fFRUVuvXWW5WSkqLnn39eP/vZz5SXl6cJEyZIkv72t7/p1ltv1aRJkzRjxgwdPXpUX3zxhdavX68pU6ZIkm688Ubl5eVp+vTp6tu3r/bu3av33ntPmzZt0jnnnCPJDC/Hjh2rAQMGaO7cuYqLi9Ozzz6rn/70pyoqKtKgQYO8PhcAAAgCAwAAIEieffZZQ5LLr8TExNp+W7ZsMSQZbdq0MUpKSmrb169fb0gyZs6cWdt21llnGV26dDH27t1b2/b5558bcXFxxtVXX13bdvXVVxtxcXHGRx991Ghc1dXVTuPLycmpbTMMw5g5c6ZhtVqN/fv3e7y+8847zxgwYIBT24YNGwxJxgsvvGAYhmF8+umnhiRj2bJlHs/lyjXXXOPysxs2bJjT+Lds2VL7mh49ehiSjLVr19a27dq1y0hMTDR+85vf1LYdPXrUsNvtTu+3ZcsWIzEx0bj33nud2iQZzz77rMexFhQUNHmdubm5hiSjqKiotu3gwYNGz549jaysrNrxjB8/3jj99NM9vl+HDh2Mm2++2e3x6upqo1evXsaYMWOcfrYVFRVGz549jVGjRnl9LgAAEBxs3wMAAEH3+OOPa9WqVU5fb775ZqN+l156qdLT02u/HzRokAYPHqwVK1ZIksrKyvTZZ59p6tSp6ty5c22/M888U6NGjartV11drddee02XXHKJy1pWFovF6fvrr7/eqS07O1t2u93l1rz6rrjiCn3yySf673//W9v28ssvKzExUePHj5ek2hVNb731lioqKjyez5XWrVs3+uwefvhhj6/p27evsrOza79PTU3Vaaedpv/973+1bYmJiYqLM/8paLfbtXfvXrVr106nnXZa0LatrVixQoMGDdLQoUNr29q1a6frr79eW7du1TfffCNJ6tixo0pKSvTRRx+5PVfHjh21fv16bd++3eXxzz77TN9//72mTJmivXv3as+ePdqzZ48OHz6skSNHau3ataqurvbqXAAAIDgIpQAAQNANGjRIOTk5Tl8jRoxo1K9Xr16N2k499dTamkmOkOi0005r1K9Pnz61ocPu3btVXl6uM844w6vxnXjiiU7fd+rUSZJqa0K5c9lllykuLq52m59hGFq2bJnGjh2r5ORkSVLPnj01a9YsPf300zrhhBM0ZswYPf74417Xk7JarY0+uwEDBvh0PY5rqn891dXVevTRR9WrVy8lJibqhBNOUGpqqr744gu/a12588MPP7j92TmOS9Idd9yhdu3aadCgQerVq5duvvnmRnWgHnzwQX311VfKzMzUoEGDNG/ePKfQ7fvvv5ckXXPNNUpNTXX6evrpp3Xs2LHa62zqXAAAIDgIpQAAQIvn7g52hmF4fF337t2VnZ2tV155RZL04Ycfatu2bbriiiuc+j388MP64osv9Lvf/U5HjhzRrbfeqtNPP10lJSWBuYAGvLmeP/zhD5o1a5YuuOAC/eMf/9Bbb72lVatW6fTTT69dQRQuffr00ebNm/XSSy9p6NChWr58uYYOHaq5c+fW9rn88sv1v//9T4sXL1b37t21YMECnX766bUr8BzXsGDBgkYrzRxf7dq18+pcAAAgOCh0DgAAIoZjdUt93333XW3x8h49ekiSNm/e3Kjft99+qxNOOEFt27ZVmzZtlJyc7PLOfYF2xRVX6KabbtLmzZv18ssvKykpSZdcckmjfv369VO/fv00e/ZsffDBBxoyZIiefPJJ3X///UEfoyt5eXkaMWKE/v73vzu179+/XyeccEJQ3rNHjx5uf3aO4w5t27bVFVdcoSuuuEKVlZWy2Wx64IEHdNddd6l169aSpLS0NN1000266aabtGvXLp1zzjl64IEHNHbsWJ188smSpOTkZOXk5DQ5Nk/nAgAAwcFKKQAAEDFee+01lZaW1n6/YcMGrV+/vjYYSEtL01lnnaXnn39e+/fvr+331Vdf6e2339a4ceMkSXFxcbr00kv1+uuv6+OPP270Pk2tgPLFxIkTZbVatXTpUi1btkwXX3yx2rZtW3u8vLxcx48fd3pNv379FBcXp2PHjgVsHL6yWq2NPodly5Y5ff6BNm7cOG3YsEHr1q2rbTt8+LCeeuopZWVlqW/fvpKkvXv3Or2uVatW6tu3rwzDUFVVlex2e6Mthl26dFH37t1rP9MBAwbo5JNP1kMPPaRDhw41Gsvu3bslyatzAQCA4GClFAAACLo333yzdjVMfeeff75OOumk2u9POeUUDR06VL/+9a917NgxLVy4UCkpKfrtb39b22fBggUaO3aszjvvPE2bNk1HjhzR4sWL1aFDB82bN6+23x/+8Ae9/fbbGjZsmK6//nr16dNHZWVlWrZsmd577z117NgxINfWpUsXjRgxQo888ogOHjzYaOveO++8o+nTp+uyyy7TqaeequPHj+v//u//ZLVaNXHixICMoTkuvvhi3Xvvvbr22mt1/vnn68svv9SLL77o9PNojuXLl7v8WV9zzTW68847tXTpUo0dO1a33nqrOnfurOeff15btmzR8uXLawuvjx49Wt26ddOQIUPUtWtXbdq0SY899pguuugitW/fXvv371dGRoYmTZqk/v37q127dlq9erU++uij2iLwcXFxevrppzV27Fidfvrpuvbaa5Wenq7S0lIVFBQoOTlZr7/+ug4ePNjkuQAAQHAQSgEAgKCbM2eOy/Znn33WKQS5+uqrFRcXp4ULF2rXrl0aNGiQHnvsMaWlpdX2ycnJ0cqVKzV37lzNmTNHCQkJGjZsmP70pz+pZ8+etf3S09O1fv163X333XrxxRdVXl6u9PR0jR07VklJSQG9viuuuEKrV69W+/bta1drOfTv319jxozR66+/rtLSUiUlJal///568803de655wZ0HL743e9+p8OHD2vJkiV6+eWXdc455+jf//637rzzTr/O+9JLL7lsHz58uIYOHaoPPvhAd9xxhxYvXqyjR4/qzDPP1Ouvv66LLrqotu8NN9ygF198UY888ogOHTqkjIwM3XrrrZo9e7YkKSkpSTfddJPefvtt5efnq7q6WqeccoqeeOIJ/frXv3Z6z3Xr1um+++7TY489pkOHDqlbt24aPHiwbrjhBp/OBQAAAs9iBHL9OgAAQDNs3bpVPXv21IIFC3TbbbeFezgAAAAIAWpKAQAAAAAAIOQIpQAAAAAAABByhFIAAAAAAAAIOWpKAQAAAAAAIORYKQUAAAAAAICQI5QCAAAAAABAyMWHewCRrrq6Wtu3b1f79u1lsVjCPRwAAAAAAICIZhiGDh48qO7duysuzv16KEKpJmzfvl2ZmZnhHgYAAAAAAEBUKS4uVkZGhtvjhFJNaN++vSTzg0xOTg7zaJpWVVWlt99+W6NHj1ZCQkK4h4MoxByCv5hD8AfzB/5iDsEfzB/4izkEf8XKHCovL1dmZmZtpuIOoVQTHFv2kpOToyaUSkpKUnJyclRPYIQPcwj+Yg7BH8wf+Is5BH8wf+Av5hD8FWtzqKkySBQ6BwAAAAAAQMgRSgEAAAAAACDkCKUAAAAAAAAQctSUAgAAAAAAIWG321VVVRXuYUSsqqoqxcfH6+jRo7Lb7eEejlsJCQmyWq1+n4dQCgAAAAAABJVhGNqxY4f2798f7qFENMMw1K1bNxUXFzdZJDzcOnbsqG7duvk1TkIpAAAAAAAQVI5AqkuXLkpKSor4wCVcqqurdejQIbVr105xcZFZcckwDFVUVGjXrl2SpLS0tGafi1AKAAAAAAAEjd1urw2kUlJSwj2ciFZdXa3Kykq1bt06YkMpSWrTpo0kadeuXerSpUuzt/JF7hUCAAAAAICo56ghlZSUFOaRIJAcP09/aoQRSgEAAAAAgKBjy15sCcTPk1AKAAAAAAAAIUcoBQAAAAAAEAJZWVlauHBhuIcRMQilAAAAAABAxLPbpcJCaelS89FuD957WSwWj1/z5s1r1nk/+ugjXX/99X6Nbfjw4crNzfXrHJGCu+8BAAAAAICIlp8vzZghlZTUtWVkSIsWSTZb4N+vrKys9vnLL7+sOXPmaPPmzbVt7dq1q31uGIbsdrvi45uOWFJTUwM70CjHSikAAAAAABCx8vOlSZOcAylJKi012/PzA/+e3bp1q/3q0KGDLBZL7ffffvut2rdvrzfffFMDBgxQYmKi3nvvPf33v//V+PHj1bVrV7Vr104/+clPtHr1aqfzNty+Z7FY9PTTT2vChAlKSkrSaaedphUrVvg19uXLl+v0009XYmKisrKy9PDDDzsdf+KJJ9SrVy+1bt1aXbt21aRJk2qP5eXlqV+/fmrTpo1SUlKUk5Ojw4cP+zUeTwilAAAAAABAyBiGdPiwd1/l5dKtt5qvcXUeyVxBVV7u3flcnae57rzzTv3xj3/Upk2bdOaZZ+rQoUMaN26c1qxZo08//VQXXnihLrnkEm3bts3jee655x5dfvnl+uKLLzR27FjdcMMN2rdvX7PG9Mknn+jyyy/XlVdeqS+//FLz5s3T3Xffreeee06S9PHHH+vWW2/Vvffeq82bN2vlypW64IILJJmrwyZPnqxf/vKX2rRpkwoLC2Wz2WQE8kNrgO17iH3Vdml3kXSkTGqTJqVmS3HWcI8KAAAAAFqkigqp3u43vxiGuYKqQwfv+h86JLVtG5j3vvfeezVq1Kja7zt37qz+/fvXfn/ffffp1Vdf1b/+9S9Nnz7d7XmmTp2qyZMnS5IeeOABLV68WBs2bNC4ceN8HtMjjzyikSNH6u6775YknXrqqfrmm2+0YMECTZ06Vdu2bVPbtm118cUXq3379urRo4fOPvtsSWYodfz4cdlsNvXo0UOS1K9fP5/H4AtWSiG2FedL/8qS1oyQPphiPv4ry2wHAAAAAKCZBg4c6PT9oUOHdNttt6lPnz7q2LGj2rVrp02bNjW5UurMM8+sfd62bVu1b99eu3btataYNm3apCFDhji1DRkyRN9//73sdrtGjRqlHj166KSTTtIvfvELvfjii6qoqJAk9e/fXyNHjlS/fv102WWX6W9/+5t+/PHHZo3DW4RSiF3F+VLRJKmiwcbjilKznWAKAAAAAEIuKclcseTNl7fllVas8O58SUmBu462DZZc3XbbbXr11Vf1hz/8QUVFRfrss8/Ur18/VVZWejxPQkKC0/cWi0XV1dWBG2g97du318aNG7V06VKlpaVpzpw56t+/v/bv3y+r1apVq1bpzTffVN++fbV48WKddtpp2rJlS1DGIhFKIVZV26VPZkhytfe1pu2TXLMfAAAAACBkLBZzC503X6NHm3fZs1jcnysz0+znzfncnScQ3n//fU2dOlUTJkxQv3791K1bN23dujV4b+hCnz599P777zca16mnniqr1SxjEx8fr5ycHD344IP64osvtHXrVr3zzjuSzEBsyJAhuueee/Tpp5+qVatWevXVV4M2XmpKIXbUrx11dGfjFVJODKmi2OzfdXioRghfUAsMAAAAaPGsVmnRIvMuexaLc6FyR8C0cKHZL9x69eql/Px8XXLJJbJYLLr77ruDtuJp9+7d+uyzz5za0tLS9Jvf/EY/+clPdN999+mKK67QunXr9Nhjj+mJJ56QJL3xxhv63//+pwsuuECdOnXSihUrVF1drdNOO03r16/XmjVrNHr0aHXp0kXr16/X7t271adPn6Bcg0QoBV9EckhQnG+ujPIYRLmwY01kXk9L5+rnmZQhDVgkZdrCNy4AAAAAIWezSXl55l32Sur9iZCRYQZStgj5E+GRRx7RL3/5S51//vk64YQTdMcdd6i8vDwo77VkyRItWbLEqe2+++7T7Nmz9corr2jOnDm67777lJaWpnvvvVdTp06VJHXs2FH5+fmaN2+ejh49ql69emnp0qU6/fTTtWnTJq1du1YLFy5UeXm5evTooYcfflhjx44NyjVIhFLwViSHBI7aUS636jXh6/vrnkfK9bR07n6ejlpg2Xn8jAAAAIAWxmaTxo+XioqksjIpLU3Kzg7NCqmpU6fWhjqSNHz4cBlG478/s7KyarfBOdx8881O3zfczufqPD/88IOSk5PdjqewsNDjeCdOnKiJEye6PDZ06FC3r+/Tp49Wrlzp8dyBRijVEvi6wqlh/6N7pPcvV0SGBB5rR/koFNcTyavNIkGTtcAsZi2w9PF8bgAAAEALY7VKw4eHexQIJEKpWOfrCidX/S1WRVRI4FPtKF8E+XqCvdosFgKv3UXUAgMAAACAFoJQKpY1tQ1q6MtSYmrTK6IMT3eocxMSBCsgaW7tKK8FKfRozpY0Xz7DWAm8jpR5169hLTDJv9WAzbked+eIhXAQAAAAAEKAUCpWGU1tg5L0/mTnwMntiigvbFtuPqZmS6X/dB+QpI9v/h/s/tSOOudRqXVX6cA3znWk3Kl/Pf6GG01uSZO04Ubp+BEpKd33zzDY2ys9BV6ufp5S88OaNmnejan+z7BVivlYubfx+LxdDejr9bj7+fSYLP2wNDJrrwEAAABAhCGUilGW3e81vZqo4QoojyuimvD9Y+ZXqxTncMCholQqmtj4uLd/sFfbpY+bUzvKYr7HqbeYAcjOQu9CKcf1eAorvA2OvNlieGy3tO7n5nNfP0OP2yvVOPDyFBBV22XZ9a7Sj6+VZVdb6fh+D4GXi7G4C4g8hTX1P6vEVMnaRrIf8fx51ef2s/JhNaAv1+P251MibVrgfiwUaAcAAAAAJ4RSseqol9ugAs3VH+uSakOAhscb/sFefdzcPnfwP9Kh/5iPB/8j7f9cOuLrlj2L+TBgYd2KnNRsMwypKJVXAZensMKX4MgXvn6GTYWJ9QMvTwFRTXt8RYkGStK7jzQdeDUci89hjZ+flVu+rgb04Xp8HisF2gEAAADAFUKpWNXay21QYecID64yg5HDWyXjeGBOnZRhBlL1V6fEWc3VOUWTZIZWTQVTPoQVnvpHCrcBkZt2f1bPNamJzyoQYVUgVwP6hQLtAAAAANAQoVSMMlKH+rYiyBsWa/D+qK8+aq6MkqS4RKndSVL7U6R2p5iPxw9Ln/226fM4akd5qleVaTNXZgW1YDr8YzG38Y1YLR3b5X0tsEjnbSF3AAAAAGgBCKVilcXXFUEeT2Y+DFlq1ufZttystxRop/9eOuUGs/aRJc75WLVd+u7PHkK2BrWjmpJpq6tlFKzrgR8Mc7tmnFXKmux9LbBI520hdwAAAABoAeKa7oKo5VgRlJTu3G5pIrRpeDwpwzzPiZeZW49OnBjQYdbqliO1zWwcSEl12+7MATY46KJ2lBfshlWFm4ZrzfdBuh747ZtPyrR0qVT4TbaMNhlq/LOPFhYpKbPubn4AAAAAWoThw4crNze39vusrCwtXLjQ42s6deqk1157LajjihSslIp1mTbZu43Xl+8UqWJvmZJS0tTv1D2yrru8pvxy3aojQxZZJNnPW6ovN6fW9f9ptqwJVtntUlGRtGN7ti6Ny1BidanT6+vOY7I0aHMfJ9SscmrqD/aakM34eIYs9YqeG20yZBm4UPbuNhUVSmVlUlqalJ0tWa2qHXf99n/+U5oxQyopkeIs2dq6KEPpnUsVZwnQVkcP/pP8qHaVp2pg3EwlVO9x+RlKjT8zV5+r8zGrLApNzSTPP8/Auem2NL27SZKs+tWYRXrqanPln/O8NfkznuZcj6ufj8Vlu/m/K19DUwAAAAANuLuLeBBccsklqqqq0sqVKxsdKyoq0gUXXKDPP/9cZ555pk/n/eijj9S2bVu/xjZ16lTt378/JoIrQqkYl58vzZhhVUnJ8Nq2jAzpgRvzlNNphrp3rAt3tu/P0JofF+r3d9hUUq/UUkaGNHmytHSpatqtmjBwkfJyJ8kwLIqLqwsIqqstksXQj4dTlNKurkj1vsMp6py0V4YsTsFPtWGRxSJZvPyDPf8jm2bmjlfPdkVK61imsv1p2nIoW1dcaa03PnfjNqWkSHvr1c+uNqya8YJ5PdXVztdj1Dy1uEgsXB3z3N+i7QcydNrPb1G1YdWEgW3Mz9DVZyJDP1akqHPbuoHuPZSilLZ7Ve3yM5d++cxSbS1LVfdOpVr4i5k6of0elyGbYbi/HnftdsOq+Li6wMvdz9PV9VcbdWFNnJefVXW1RSX7MlT0bV1Q+fe3bdq7N0+Lp85Qeqe6H+jeQymySE7z7Xi1VVaLPUjX4/rns31/pr4/dqVOTVza6H9XxakLdW79gvsAAAAAfFOc37gucFKGuaMmCP/WnjZtmiZOnKiSkhJlZGQ4HXv22Wc1cOBAnwMpSUpNTQ3UEGMC2/diWH6+NGmScyAjmd9fM9umzOlbNfz+Ak1+bImG31+gE6dv0TWzbS77L1jgfJ5XP7Zp0sI8lf7ovDWwZF+GJi1cri437nQ6d5cbdmriwuUq3eeqf57yP2r6l4jjerYVW/XupuF6ad1kvbtpuLYVWxuNz924JedAqqnr2XMwRVJN8FNPdbW5VmfvoRSf+t/y7EJVG1bn92z4mezN0MSFy5V6g/Nn2PXGms/Q5Weep+ffuUzvbhqupR9cpRv//qSbcdQ8Nsiq3LdbZMiiK/+81Kuf556DKY0+k5K9mXrwjdtVui+jUV93n5UsUu7/1X1WkhkQvfqxTSfesrXR59Jwvl3555dkyOLm5+Dv9bj++Zw4fYtGzHpQmdO36vWNF0mS/l54rXrcskXnX2FTfr4AAAAANEdxvlkvueGNqipKzfbiwP9j++KLL1Zqaqqee+45p/ZDhw5p2bJlmjZtmvbu3avJkycrPT1dSUlJ6tevn5YuXerxvA23733//fe64IIL1Lp1a/Xt21erVq3ye+zvvvuuBg0apMTERKWlpenOO+/U8eN1d7nPy8tTv3791KZNG6WkpCgnJ0eHDx+WJBUWFmrQoEFq27atOnbsqCFDhuiHH37we0zusFIqRtnt5vY0o/FCmVrVhhnuNNerH9v0z0/GK7t33aqlom+za4OEhuf21L/oRqlDB3O7nbvrufFGz9fjL3fjGz/gn1p09QxlptT9AizZl6Hc/1voc/9XP7Z59Z7N+Qwb9pu0MM/FODK1dN2VmnL+Ui/bXY/b01gkuRzf716e79dn5eBu3jZsc339gbseV+/pGN/XJWfoknP+rfIjHWSvtspikXJzpfHj3c9xAAAAoMUwDMle4V3farv08a1yfcOrmuIZH8+QuuZ4t5XPmuR6u0YD8fHxuvrqq/Xcc8/p97//vSw1r1m2bJnsdrsmT56sQ4cOacCAAbrjjjuUnJysf//73/rFL36hk08+WYMGDWr60qqrZbPZ1LVrV61fv14HDhxwqj/VHKWlpRo3bpymTp2qF154Qd9++62uu+46tW7dWvPmzVNZWZkmT56sBx98UBMmTNDBgwdVVFQkwzB0/PhxXXrppbruuuu0dOlSVVZWasOGDbXXHgyEUjHqvfcsjVYIBYOvwZa7/rt3Szk5gRtXc7kaX7CCI0/v6esYXfE0DlcBkad2X8fiLqzx97PyRXPO7cv1eLLvcGdJUue2+ySZ/59bXGzWNhvu26kAAACA2GOvkF5pF6CT1dy5O6+Dd90vPyTFe1fT6Ze//KUWLFigd999V8Nr/iH/7LPPauLEierQoYM6dOig2267rbb/LbfcorfeekuvvPKKV6HU6tWr9e233+qtt95S9+7dJUn333+/LrroIu+uxYUnnnhCmZmZeuyxx2SxWNS7d29t375dd9xxh+bMmaOysjIdP35cNptNPXr0kCT169dPkrRv3z4dOHBAF198sU4++WRJUp8+fZo9Fm8QSsWosrJwj8B33bubq6VcOXBA2r49tOOpL1jBUbC5G4ev7cEUzPcM189h36GaUKrdPqf2aPzfJQAAANBS9e7dW+eff76eeeYZDR8+XP/5z39UVFSke++9V5Jkt9v1hz/8Qa+88opKS0tVWVmpY8eOKSkpyavzb9q0SZmZmbWBlCSdd955fo1506ZNOu+885xWNw0ZMkSHDh1SSUmJ+vfvr5EjR6pfv34aM2aMRo8erUmTJqlTp07q3Lmzpk6dqjFjxmjUqFHKycnR5ZdfrrS0NL/G5AmhVIwK4pwJmhdfdL+KpLBQGjEilKMBms9dKBWN/7sEAAAAAs6aZK5Y8sautVLhuKb7DV8hdbnAu/f2wbRp03TLLbfo8ccf17PPPquTTz5Zw4YNkyQtWLBAixYt0sKFC9WvXz+1bdtWubm5qqys9Ok9QslqtWrVqlX64IMP9Pbbb2vx4sX6/e9/r/Xr16tnz5569tlndeutt2rlypV6+eWXNXv2bK1atUrnnntuUMZDofMYNXSooYwMr7bKhp3FImVmStnZ7vtkZytqrgdouH3PmzkOAAAAtBgWi7mFzpuvbqPNu+zJ3R+DFikp0+znzfl8/KPy8ssvV1xcnJYsWaIXXnhBv/zlL2tXIb3//vsaP368fv7zn6t///466aST9N1333l97j59+qi4uFhl9bZUfPjhhz6Nz9U5161bJ6NeQeb3339f7du3r72LoMVi0ZAhQ3TPPffo008/VatWrfTqq6/W9j/77LN111136YMPPtAZZ5yhJUuW+DUmTwilYpTVKi1aZD4PZZCTkuLbezr6LVzouQB0IK/H8fqUFM/9mnMOX68/0t8zHGLhOh137Ovcbp/XcxwAAACAC3FWaUDNH4ONgqma7wcs9K7IeTO0a9dOV1xxhe666y6VlZVp6tSptcd69epVu+po06ZNuuGGG7Rz506vz52Tk6NTTz1V11xzjT7//HMVFRXp7rvv9uq1Bw4c0Geffeb0VVxcrJtuuknFxcW65ZZb9O233+qf//yn5s6dq1mzZikuLk7r16/XH/7wB3388cfatm2b8vPztXv3bvXp00dbtmzRXXfdpXXr1umHH37Q22+/re+//z6odaUIpWKYzSbl5Unpzne5V2amdPvt5sojf9tfeUUqKJCWLDEfd+6Uli/3/j0zMswx2lzfaC0o15ORYY5x507nsS9b5v85fL3+lJTG4Uug3tOXcweqPRDvGUnX2dxz127fa7tPGRmG13McAAAAgAuZNik7T0pq8MdAUobZnhncf2xPmzZNP/74o8aMGeNU/2n27Nk655xzNGbMGA0fPlzdunXTpZde6vV54+Li9Oqrr+rIkSMaNGiQfvWrX+m+++7z6rWFhYU6++yznb7uuecepaena8WKFdqwYYP69++vG2+8UdOmTdPs2bMlScnJyVq7dq3GjRunU089VbNnz9bDDz+ssWPHKikpSd9++60mTpyoU089Vddff71uvvlm3XDDDT59Xr6wGPXXdKGR8vJydejQQQcOHFBycnK4h9OkqqoqrVixQuPGjVNCQoIkyW437/pVVmbWtMnONldsBKrdlUCcw51oGLcv55GC956+nttulwoKjuvNNz/T2LFnacSIeJ8/2+a8ZziuM5jX88KzR3RtTXFDu61c1tbt3V9QDHL1ewjwFvMH/mIOwR/MH/iLOeTa0aNHtWXLFvXs2VOtW7du/omq7dLuIulImdQmTUrNDtoKqXCprq5WeXm5kpOTFRcX2euIPP1cvc1Soi6Uevzxx7VgwQLt2LFD/fv31+LFi93eavFvf/ubXnjhBX311VeSpAEDBugPf/iDV7dmdIiFUArwBXPIf4cPS3HL2qhNq6P68YKt6pTRI9xDCinmEPzB/IG/mEPwB/MH/mIOuRawUKoFaGmhVGRfYQMvv/yyZs2apblz52rjxo3q37+/xowZo127drnsX1hYqMmTJ6ugoEDr1q1TZmamRo8erdLS0hCPHEBL0ratdOCIuYVv23/2NdEbAAAAAFqmqAqlHnnkEV133XW69tpr1bdvXz355JNKSkrSM88847L/iy++qJtuuklnnXWWevfuraefflrV1dVas2ZNiEcOoKWpsJuh1I5thFIAAAAA4Ep8uAfgrcrKSn3yySe66667atvi4uKUk5OjdevWeXWOiooKVVVVqXPnzm77HDt2TMeOHav9vry8XJK5DLOqqqqZow8dxxijYayITMyhwDge10mStKd0T4v7LJlD8AfzB/5iDsEfzB/4iznkWlVVlQzDUHV1taqrq8M9nIjmqLDk+LwiWXV1tQzDUFVVlawNCgN7+7+BqAml9uzZI7vdrq5duzq1d+3aVd9++61X57jjjjvUvXt35eTkuO0zf/583XPPPY3a3377bSXVFC6OBqtWrQr3EBDlmEP+yaw0awiUbtmqFStWhHk04cEcgj+YP/AXcwj+YP7AX8whZ/Hx8erWrZsOHTqkysrKcA8nKhw8eDDcQ2hSZWWljhw5orVr1+r48eNOxyoqKrw6R9SEUv764x//qJdeekmFhYUeC6vdddddmjVrVu335eXltbWooqXQ+apVqzRq1CgK66FZmEOBsf3V16TjUqLsGjduXLiHE1LMIfiD+QN/MYfgD+YP/MUccu3YsWPatm2bkpKSomqxRzgYhqGDBw+qffv2slgs4R6ORxUVFWrTpo2GDRumxMREp2OOXWdNiZpQ6oQTTpDVatXOnTud2nfu3Klu3bp5fO1DDz2kP/7xj1q9erXOPPNMj30TExMbfZiSlJCQEFW/VKJtvIg8zCH/JJ9wgrRDqj76o6zWBEX4jTOCgjkEfzB/4C/mEPzB/IG/mEPOrFarrFarduzYodTUVLVq1SriA5dwqa6uVmVlpY4dOxaxd98zDEOVlZXavXu3rFarkpKSGo3V2/kfNaFUq1atNGDAAK1Zs0aXXnqpJNUWLZ8+fbrb1z344IN64IEH9NZbb2ngwIEhGi2Ali45tbO0Q0puvU+lpVJmZrhHBAAAAIRHXFycevbsqbKyMm3fvj3cw4lohmHoyJEjatOmTcQHd0lJSTrxxBP9Cs+iJpSSpFmzZumaa67RwIEDNWjQIC1cuFCHDx/WtddeK0m6+uqrlZ6ervnz50uS/vSnP2nOnDlasmSJsrKytGPHDklSu3bt1K5du7BdB4DYZ21t3lChc9t9+u47QikAAAC0bK1atdKJJ56o48ePy263h3s4Eauqqkpr167VBRdcENGr7axWq+Lj4/0OzqIqlLriiiu0e/duzZkzRzt27NBZZ52llStX1hY/37Ztm1NC95e//EWVlZWaNGmS03nmzp2refPmhXLoAFqaxJpQqt0+ffOdNHJkmMcDAAAAhJnFYmFrYxOsVquOHz+u1q1bt4jPKapCKUmaPn262+16hYWFTt9v3bo1+AMCAFdamaFUSru92rw5zGMBAAAAgAgUmVWzACDatapbKfXdd2EeCwAAAABEIEIpAAiGxPo1pYwwDwYAAAAAIg+hFAAEQ81KqdatjmlH6RFVVoZ5PAAAAAAQYQilACAY4tvJsJhl+zom7dP//hfm8QAAAABAhCGUAoBgsFhkcdrCF+bxAAAAAECEIZQCgGCh2DkAAAAAuEUoBQDB0oqVUgAAAADgDqEUAAQLK6UAAAAAwC1CKQAIlkRCKQAAAABwh1AKAIKl3va9sjLp4MEwjwcAAAAAIgihFAAES00olZ66T5L0/ffhHAwAAAAARBZCKQAIlsQUSVJmFzOU2rw5nIMBAAAAgMhCKAUAwVKzUqprJzOUoq4UAAAAANQhlAKAYKlX6FwilAIAAACA+gilACBYalZKtU8klAIAAACAhgilACBYalZKJVrqQinDCOeAAAAAACByEEoBQLDUrJSyVh9WYsIxlZdLu3aFeUwAAAAAECEIpQAgWBKSJYv5a7bfaT9Kkp54QioslOz2MI4LAAAAACIAoRQABIslTmrVSZJUddjcwnfvvdKIEVJWlpSfH8axAQAAAECYEUoBQBAdrDS38LVL2OfUXloqTZpEMAUAAACg5SKUAoAgsdul738wQ6nO7ZxDKUfB89xctvIBAAAAaJkIpQAgSIqKpB37zFAqpd3eRscNQyouNvsBAAAAQEsTH+4BAECsKiuT7Idcr5Rq2A8AAAAAWhpWSgFAkKSlSfsO14RSbd2HUmlpoRoRAAAAAEQOQikACJLsbOl4nPuVUhaLlJlp9gMAAACAloZQCgCCxGqVRo51HUpZLObjwoVmPwAAAABoaQilACCI+v/EDKXSUpxDqYwMKS9PstnCMSoAAAAACD9CKQAIplZmKJU9aJ8uucRs+sUvpC1bCKQAAAAAtGyEUgAQTIlmKGWp3KfBg82m+Hi27AEAAAAAoRQABFPNSilV7lNmpvm0uDh8wwEAAACASEEoBQDB5AilqsqVmV4lSSopCeN4AAAAACBCEEoBQDC16lj7tEfafknmSinDCM9wAAAAACBSEEoBQDDFxUsJHSTV3YHv8GFp//4wjgkAAAAAIgChFAAEW80WvjZx+5SSYjaxhQ8AAABAS0coBQDBlkixcwAAAABoiFAKAIKt3h34MjLMp6yUAgAAANDSEUoBQLA5QqljrJQCAAAAAAdCKQAItsSaQlKslAIAAACAWoRSABBsragpBQAAAAANEUoBQLAlsn0PAAAAABoilAKAYHNT6NwwwjckAAAAAAg3QikACDYXoVRFhfTjj+EbEgAAAACEG6EUAARbve17rVtLJ5xgfkuxcwAAAAAtGaEUAARb7UqpvZJEXSkAAAAAEKEUAARfbSi1X6q2127hI5QCAAAA0JIRSgFAsLXqVPPEkKoO1K6UYvseAAAAgJaMUAoAgs3aSopvZz6v3Mf2PQAAAAAQoRQAhEarumLnju17rJQCAAAA0JIRSgFAKDjuwMdKKQAAAACQRCgFAKHRqi6Uqr9SyjDCNyQAAAAACCdCKQAIBRfb944ckfbtC9+QAAAAACCcCKUAIBTqbd9LTJS6dDG/ZQsfAAAAgJaKUAoAQiGho/m4Z520s1AnZtolUewcAAAAQMtFKAUAwVacL/3nr+bzspXSmhF688YsTRiYz0opAAAAAC0WoRQABFNxvlQ0Sao64NSc0qZUebmTlHwgP0wDAwAAAIDwIpQCgGCptkufzJDU+BZ7FoshGdKFqblmPwAAAABoYQilACBYdhdJFe6LRsXFGUppU2z2q6/aLu0slLYuNR8JrQAAAADEoPhwDwAAYtaRMt/7Feebq6vqh1lJGdKARVKmLbDjAwAAAIAwYqUUAARLmzSvuhmta/o56k81XF1VUWq2F1N/CgAAAEDsIJQCgGBJzTZXOcni8nB1tUXb9mRqrzXbY/2p2rZPctnKBwAAACBmEEoBQLDEWc1td5IaB1MWySLl/t9CFZdYm6w/JRlShYv6UwAAAAAQpQilACCYMm1Sdp6UlO7cnpCsO9/I06sf21RSoubVnwIAAACAKEYoBQDBlmmTfrZVGlkgnXSt2da+t74/ahYuLy6W1/WnvO4HAAAAABGOUAoAQiHOKnUdLp15v/n9vvU6/aTtkmpCqSbqT0kWKSnT7AcAAAAAMYBQCgBCKam7lHKuJOmCk16TJHP7Xm39KVeFzmuCqgELzX4AAAAAEAMIpQAg1DLNbXtndnpVUs1KKUd7x/6N+ydlmHWpal4HAAAAALGAUAoAQi1zgiSpqwrUqe0+c6WUJB38j7T/c/P5uc/X9R/9IYEUAAAAgJhDKAUAodb+FKljP1lk18Vnv6GSEskwJP3nr+bxtLHSSVfXFTU/sj1sQwUAAACAYCGUAoBwyDBXS00Y+KqOHZOe/utRVW1+1jzW69fmY1Km+VhR7OIEAAAAABDdCKUAIBxqtuNd2H+lkhIPa+2Ly5RQvVclP56o/PXjzD6EUgAAAABiGKEUAIRB/jtn6n+7eqpNq6OaNfZh3X3pfZKkv67+lSZdZlV+vgilAAAAAMQ0QikACDG7XZqRa9GXxf0kSfddNlenpn0vSfp1zl80YWC+cnOl6jY1odRhQikAAAAAsYdQCgBCrKhI+km3fP3snH81Otatww4tmzFJA7vma9MPrJQCAAAAELsIpQAgxHZst2vR1TNkuDgWF2dIhrTwF7kq/THdbCSUAgAAABCD4sM9AABoaXqnFClTJW6Px8UZOvGEYpV32i79KOlIqVR9XIrjVzYAAACA2MFKKQAIsTN7lXnVr++pxyRLvGRUS0e8ew0AAAAARAtCKQAIsbi2ad71a5cuJbGFDwAAAEBsIpQCgFBLzZaSMmTI4vKwIYuUlFnTj2LnAAAAAGIToRQAhFqcVRqwSBapUTBlyGK2DFho9iOUAgAAABCjCKUAIBwybVJ2niyO7Xk1LEkZUnaeeVyS2p5oPh4mlAIAAAAQW7iVEwCES6ZNSh+vovwiPfFImZK7pumvy7PNFVIOrJQCAAAAEKMIpQAgnOKs6tJvuF5aJ7VtK/1FDZawEkoBAAAAiFFs3wOAMDv5ZCkhQTp8WCpumD3VhlLbQj4uAAAAAAgmQikACLP4eOm008zn33zT4KAjlDq6S7IfC+m4AAAAACCYCKUAIAL06WM+btrU4EBiimRtbT6vKAnpmAAAAAAgmAilACAC9O1rPjZaKWWxUFcKAAAAQEyKulDq8ccfV1ZWllq3bq3Bgwdrw4YNHvsvW7ZMvXv3VuvWrdWvXz+tWLEiRCMFAO+5DaUkKelE85FQCgAAAEAMiapQ6uWXX9asWbM0d+5cbdy4Uf3799eYMWO0a9cul/0/+OADTZ48WdOmTdOnn36qSy+9VJdeeqm++uqrEI8cADyrH0oZRoODbVkpBQAAACD2RFUo9cgjj+i6667Ttddeq759++rJJ59UUlKSnnnmGZf9Fy1apAsvvFC33367+vTpo/vuu0/nnHOOHnvssRCPHAA869VLslqlAweksrIGBx3b9w4TSgEAAACIHVETSlVWVuqTTz5RTk5ObVtcXJxycnK0bt06l69Zt26dU39JGjNmjNv+ABAuiYnSySebz93ega9iW0jHBAAAAADBFB/uAXhrz549stvt6tq1q1N7165d9e2337p8zY4dO1z237Fjh9v3OXbsmI4dq7vtenl5uSSpqqpKVVVVzR1+yDjGGA1jRWRiDoVP795WffddnL76yq5hw6pr2y2JaYqXZBzepuNR8HNhDsEfzB/4izkEfzB/4C/mEPwVK3PI2/FHTSgVKvPnz9c999zTqP3tt99WUlJSGEbUPKtWrQr3EBDlmEOh16pVH0mn6q23tqlnzy9q29tXb9NPJVUd2KI3o+hmDcwh+IP5A38xh+AP5g/8xRyCv6J9DlVUVHjVL2pCqRNOOEFWq1U7d+50at+5c6e6devm8jXdunXzqb8k3XXXXZo1a1bt9+Xl5crMzNTo0aOVnJzsxxWERlVVlVatWqVRo0YpISEh3MNBFGIOhc/+/Rbl5UmHD/fQuHEZdQeqyqXXblUrHda40RdI8e3CN0gvMIfgD+YP/MUcgj+YP/AXcwj+ipU55Nh11pSoCaVatWqlAQMGaM2aNbr00kslSdXV1VqzZo2mT5/u8jXnnXee1qxZo9zc3Nq2VatW6bzzznP7PomJiUpMTGzUnpCQEFUTItrGi8jDHAq9M880HzdtilNCQr2SfwkpUkIHqeqAEip3SG36hGeAPmIOwR/MH/iLOQR/MH/gL+YQ/BXtc8jbsUdNoXNJmjVrlv72t7/p+eef16ZNm/TrX/9ahw8f1rXXXitJuvrqq3XXXXfV9p8xY4ZWrlyphx9+WN9++63mzZunjz/+2G2IBQDhdNppksUi7dkj7d7d4GBtsXPuwAcAAAAgNkTNSilJuuKKK7R7927NmTNHO3bs0FlnnaWVK1fWFjPftm2b4uLqcrbzzz9fS5Ys0ezZs/W73/1OvXr10muvvaYzzjgjXJcAAG4lJUlZWdKWLeYd+IYNq38wUzrwFaEUAAAAgJgRVaGUJE2fPt3tSqfCwsJGbZdddpkuu+yyII8KAAKjb18zlNq0qUEo1bZmpdRhQikAAAAAsSGqtu8BQKzr29d8/OabBgdqt+9tC+l4AAAAACBYCKUAIIK4D6VONB/ZvgcAAAAgRhBKAUAEcRtKtaXQOQAAAIDYQigFABGkTx/zsaxM2r+/3oGkejWlDCPUwwIAAACAgCOUAoAI0r69lJFhPt+0qd6BpJpGe4VU+WPIxwUAAAAAgUYoBQARxuUWPmtrKTHVfM4WPgAAAAAxgFAKACJM03fgI5QCAAAAEP0IpQAgwvTubT6uXi0VFkp2e80BX4udV9ulnYXS1qXmY7W9qVdEhmgdNwAAAACfxId7AACAOvn50t13m8+/+EIaMcKsMbVokWQ78UTzwOFtTZ+oOF/6ZIZUUVLXlpQhDVgkZdoCP/BAidZxAwAAAPAZK6UAIELk50uTJkm7dzu3l5aa7V/+z8uVUsX5UtEk52BHkipKzfbi/MANOpCiddwAAAAAmoVQCgAigN0uzZghGUbjY462v/5fuvlk3yfut7VV282VRnJxIkfbJ7mRtyUuVONmayAAAAAQMQilACACFBVJJSXuj186IF93j8s1vyn/VlozQvpXVuPVQ7uLGq80cmKYK612F/k54gALxbiL883PbM0I6YMp7j9DAAAAACFBKAUAEaCszP2xCQPzlZc7SanJDfb1udrWdsTDierztl+oeDueHWuat8qJrYEAAABAxCGUAoAIkJbmuj3OYteiq81tbXGWhkddbGtr4+ZEDXnbL1S8Hc/X9/u+yilatzQCAAAAMY5QCgAiQHa2eZc9S4PgKbt3kTJTSlwEUg4NtrWlZkuJJ3h4J4uUlGn2iySp2eZd9uT2QhvzdpVTtG5pBAAAAGIcoRQARACrVVq0yHxeP5hK6+jjtrbi5ZL9qOe+AxZKcdZmjTNo4qzSgEVyvZrJHS9XOUXrlkYAAAAgxhFKAUCEsNmkvDwpPb2urWy/j9va3r9COn5ISuwitUlv0ClOGrJEyrQFbMwBlWmTUof6+CIvVjlF65ZGAAAAIMYRSgFABLHZpK1bpYIC6frrpaJvs7XrkI/b2iTp2G5pwKPSyALp3BdqtvRVS5X7Az/oQLEflX783Hw+8HHp/CXS6bO9e62nVU61WwPdidAtjQAAAECMI5QCgAhjtUrDh0u/+Y1UbVh16/OLajaq+RhMbfyNGbSc9AvpjDlm2zd/kqqrAjvgQClbJR0/aK7w6nWjlDVZ6jbSu9d6WuUUZ5XOedTNwZrPNBK3NAIAAAAxjlAKACJUr15Saqr08gc2fdclT0pquB3Pkwbb2k7+ldS6i3R4q7TlH9LOQrMG1c7CyLnrXPFy8zFzomSp+b+nJguge7nKydq6rn99rTpJ2XmRu6URAAAAiGGEUgAQoSwWacgQ8/m/PrVJP9tqbsdrzra2+DZS71nm8w3XS2tGmDWo1oyQ/pXV9B3svFVtl2XXu0o/vlaWXe96H3jZK6WSf5rPT5xY115bAF1yG0x5s8rpmz+aj71/Y36G3S82v88YTyAFAAAAhAmhFABEsKE1db/fe09m8NJ1ePO3tTkKnxvHnftUlEpFk/wPporzpX9lKf7dURp47BHFvzvK+8BrZ4FUtV9q3VU6YYjzsUybuZqp4Uoxa5J3q5x2vSftfl+KayX1mWV+hqdcbx7b/b6XFwcAAAAg0AilACCCOVZKvf++ZBj1Dvi6ra3aLn1+l5u+NSf+JLf5W/mK881gq6LEud3bwMuxdS9jgutVT5n1Voqd+QezzX5MSjnX9fmq7XVbFD+93WzreXVdSJda88Ee/E46uqupqwMAAAAQBIRSABDBzjlHat1a2rtX2ry53gGP29pcFO/eXdQ4MHJSU4Pqy3m+15mqtkufzFBtuNXwvJLnwKv6uFTyqvm8/ta9hhwrxc64qyZUskv/+WvjfjUrtmq3KO790Gzv2L+uT2JnqcMZ5vPd77l/T1/UD8IiqVYXAAAAEKEIpQAggrVqJQ0ebD5/r2F24m5bW1JG421tjtpSTfn6ft/rTHkbeDmKrjs4Qpwv50nH9kitOktdhnn3nqfeYj7+569mPSoHdyu2JOmTW52vKbVmb+SuosZ9fdUwCAt0ra5IQvgGAACAACGUAoAI59jC1yiUkpy3tZ2/xHz82ZbGdZbq15byhi91prwNvOr3qx/ifP2A2WY/KpW+7t25Mm1Sm+7S0Z1ScZ7Z5nHFVo36K7a61Gxt9HellL9bF6NJSwrfAAAAEHSEUgAQ4RzFzt93V5O7fgH0rsNd12RqsgZVQzXBzsczpLI1nlfFeBt4Ofq5C3HsFd6HOHEJ0ik3ms+//XPdiitfVmw56m39+KlUdci7a2jI362L0SSQ4RurrQAAACBCKQCIeOedJ1ks0n/+I+3Y0cyTeKxB5Y4hHSmRCnIar4qpHyrYK6W41h7OU6/ouq+rmTw55TrJYpX2ra9ZcXW/d5flWLHVNlNKOlEy7HV1p3zV3K2LUnQFM4EM31htBQAAgBqEUgAQ4Tp2lM6oqcntdrWUN9zVoPJFRalUNFHK71oXKhSOkaqPunlBg6Lr/oQ4De35wAyUfFV/ZZdjC19z60o1Z+uiFH3BTKB+bi1pqyMAAACaRCgFAFGgyS183qpfg+r02c04Qc2qmMq9rg+3SnH+PjHVueh6c0OchmpX7vii3ootB8dzb0IwV3zduiiFN5hp7uqsQPzcvF1t1ZygEQAAAFGJUAoAooAjlHJZ7NxXjhpU/eb5WGeqKRbJ2kbHL3hLu+NON5syfuZcdL05IY4rTa7ccTE2qW7FloPjDnx7PpSqq3w4n+P12VJrT2NtEISFswaVP6uzAvFz83K1lcXfwvMAAACIGoRSABAFHKHUxo3S4cMBOmmz6kx5UlODyhKn71pdbjYVLzdrTjk0WXDdxWomV7xdueOQlOG8YsuhQx+pVWfJfkTat9G7czVcbdSqk4fOhnMQ1txtcP7Wn2pqdda2ZY3PX/89DbsU397DG3jxc/P2Z3bUx58tAAAAolZ8uAcAAGjaiSdK6elSaak0f76UkyNlZ0tWFzfa84mjztQnM3xceeTB0TLtiTtDRus0WY6WSWUrzRVTUl0QVjTRxQvdrGZyxduVO6fPlrqNNMMSV+e0xJmrpUr/ZQZBJwz2fL7ifNeflSVBSkyRjjaoRB+XIKXUO6e3wcyONWbfNmnS0T3SpzOd3zMpw/wcG4ZsrnizOuv9yc7b5hzbMN1t03R1nqZ+bt7+zFqnSQpU8goAAIBIxkopAIgC+fnSvn3m8wcekEaMkLKyzHa/1a8zdf4S6aerpTZ+bOtrnSZZrKo+8Qrz+60vOh9PHy+16d74de5WM7ni7YqrfvPMrYqewhLHFr6mto25W20kSUaVNPDP9T7Dd6QThphbAr+YU7fi6OjOJi9NknknQccWu/cv86/+lDdbHRvWcarc633dMEmyxEsd+3t+jyZ/ZjLnnVGt9ONrZdn1bmC3MUbT3Q4BAABaCFZKAUCEy8+XJk2SjAYLXUpLzfa8PMnmRY7jkaPOlMPARWboIYtcr7BxxSIlZchIHSrpLVWfeKWs3y00VyFVlUsJyWa3ktekI9ul+A7SkCVS1QFzFY271UzuxjvA3Rh9WHEl1d2Bb2eBtOVF8+6EDcficbVRzXtu/I30sy11r7M+KK0aIv3vGfMroAzzPT/JNUM+T9fp61ZHj8y6YRqxWjq2S2rdTfp6vrRzlbRxltR7Zt0Kr4afocdVcjUq9yp+7RgNlKR3H/FtRZgnrla4BercnlTbzVDQ3WcCAADQwrFSCgAimN0uzZjROJCS6tpyc81+AeXY1peU7txeu0qm4WqXekGQpeaP7o5nS8mnSfajUvFrdYP++g/m894zpPRxUtbkplcz+TJGX1ZcSdLhbeZjVbm07ufOBcAdq2u+nOd7LaiGW/kCzk39qYa83Tbn7XseKTF/VlmTpW4jzABTcWb42FQR9fSfSa27Nj5tfDvz0X7EuT0QdyQM190O/Sks3xCrvAAAQIxipRQARLCiIqnEQxZiGFJxsdlv+PAAv3mmzVyF03ClR+k/3aw6WWi+pqrmLnYWi9RjivTlXHML30lXS2VvSz9ulKxJ0mm3Bm+M3gZcxfnS+1c2bq8oNVf0tErxoa6S6lYl1a6s8sBibbxtrjnq159yXHv9FTqJqebqpoaBjz/qr74q3ySpunEfR+hTPyDcusTcwtgqRTr//6TK/VLrLtK6qdLxQy7eyIcVYa40WU/Lj3N74gjCGr6vq8+k4Xi9/t+bm1VerM4CAABRhFAKACJYmZc7r7zt57OG2/ok34KgrJpQascq6bu/SP/5q9l+yg1mYfBgjdEb3hQA9yWQkupWJXlbx+mcR82VQwe+MetINUf91yVlSD0mSz8sDVzhelcc1+kxfGsQ+kjS1w+Yj31uk7qPNZ/vLDRXX7lVb0WYrz9nX+522Jw55EpzgzBXWwzdhaLuwq1wbVMEAABoJkIpAIhgaV7uvPK2X8B4GwTt/0KKayVVV0of31TX3qFP0IbmNW+CI6+Z9bSUWlOfyts6Tq27mtvgdhY2P5Sqr6JE2rTA/fGGIYfPq7UaXKe3oc93i6WD/5UOficldJROvbmui7efVXNqYwXj3E2tRPLlM2ndte4Oi+9frkZBlttQtKbfhhul40fMLazuztGc1VkNV9ux4goAAAQJoRQARLDsbCkjwyxq7qqulMViHs/ODv3YmmIpeVVad6VcrhjZULNSKpyrNwJWANxFYXVv6zg5+jnuTFdRKu8Ly/uqQZFypzBEXryvi+v09jPcOLPeN9XmyjnHz97Xz8oX3r7m6E6zXlNT4Ys3K5Ga85lYrGrWz/3YbrMOmsdz1KzO+niGeXMBx8/e09ZAV6vtWHEFAACCgFAKACKY1SotWmTeZc9icQ6mLDUZwcKFZr+IYthl/WyWPP6hHYxaPr4IVAHw+vW0HJoMmRqsOPJ4N8FAaVCk3CEuz/W2Mcl5pY6r62zOZ1h10Hnljq+fVX1NreapPbenlUtxzgGRu/ClqTpRQ18263cd+Mbz9bsSiNpiHs9R87MvyKlrcrs10M1qu6ZWXPnCl1VYvq7kqrbLsutdpR9fK8uutlLaCPf9JVaDAQAQZoRSABDhbDYpL8+8C1/9oucnnCA9+aR5PNKkVH8jy9FSDz2CUMvHV/6uTjp9ttRtpOs/ZD2GTC5WHEl1dxNstHIlUzrnYTPwOFLmX/0pqfFKHnc1wqSm/2Bv1mfooq6Sx0DOaPxZSd6tWoqzSv3uk9Zf62E8DYq0NwyZjpSZxdg/bqL+2PuTAxMuhYqv9dJcbRn0IiDyqXB7w3l4dI/06UzvV3LVtMdXlGigJL37iPv+boNXVoMBABBKhFIAEAVsNmn8ePMue7NnS++/L/3615EZSElSa+NH7zoGbAtdMzR7dVLNyp1+8zyvqnAbMrlYcVT/NU0Vkfe3/pSr1U3uaoQ1FRg2+zNsEEq6+6wkKb5d41VSvtzdbt8G89GSIBlV9TpbJbkKkZoZMkVTIOWP+lsGvQiIvC/c7uXdLt2u5PKx3ZcC8gAAIGgIpQAgSlit0vDh0pVXmqHURx+Fe0TuHbV08q5joLbQNZe7MKT2j2MvVzl5Or+3dyp0aKqIfLNXeHnYBucPT4FSU+qHkjWf1fGyAn324Zs6a/AoxX9+h3TgC2njLOnkaV6uWqpXP2nfx9L3T5qHRqyULHHmOY7ubFDnytWpWkjI5I9ABEGSmn23y4DzcHdE+KYZ2y69bpeCem6vt39Gw/WE6TOMqetpxnv6PYci7Hoi+twx+p4u51AMI5QCgCgzeLD5+OGHZo0pR22pSLI3rq+MNumyHNkun+sEhZq74MjtNqOFvq2i8PZOhb6cz+fVST6Gab5q+Bl6E/pIjUPJOKuMLsNUGn9Y/buOlAY/Jb19rrT1H+aXV1zUT7K2kar21/3cti718lwBcvpss7C/N5+Jk5qfrzcriBAgEbC1OFJ5+0eYrwX0fV1tJzXedhnAc8dX7m16+2c0XE8YP8OYuZ5mvqdXW4ij6Hoi9twx/J6N5lCMby23GIar+znBoby8XB06dNCBAweUnJwc7uE0qaqqSitWrNC4ceOUkJAQ7uEgCjGHIl9lpZScLB07Jm3eLJ16arhH5Mwxhy4685ji111Z0+pitVE0bJHxpSBzqLmsqZQp9bjSxT90Mn0P0/xRbZf+ldV08fKfbWn0eTr9Dtrxurmty28N5tzOQmnNiACc10vnL5FOvLyJz0TmHfTqr9By/NwcgV9FqRlsHdvj/TnQPOcvcb4hQHNESnH1QKwAcBU0ufojjAAVAAIsiv7d3IC3WQorpQAgyrRqJQ0YIH3wgbR+feSFUg5GxgTfaypFmkCvcgokT1sD+88Pb5jWnELvDRl2c+4ERINtWf4WufdVmzTvPpMhS+uKqzf8uTnmYXwb78/Ruou0bqp0JETXGUuO7jRX1AU7xAnkfwH3pbB8IGqBedsGAPBD7G8tJ5QCgCg0eLAZSn34ofSLX4R7NB40p6YSvOcuNIuEMK05hd7rsex+z/caVR412JbVrALtLnhcmdRgm6qfn0mzzjHQUxDmYmugu9V2LUqc81bLYIY4TRVX9zYIc3WnQreF5QNVCwwAEBqxvbWcUAoAotC555qPH34Y3nF4JRICEoSHP6Hk0bLgjMlRXN1duNNUyNQmXTr3OenYrrow4P3La457sSIsEEGtL+doKsRqarWdN1sGY06187dBDXEaFOd3zCtfVzm5QpgEALElnHetDiJCKQCIQo5Q6osvpIoKKSkpvOMB3GpuKNk6rek+zVG/uLqrcKepkGngIiltpPM543xc/RSIoNaXczQVYjW12s7tlkFfuVmd5fZuly54qpvmS7urrXSKU6NAKiRcFOf3dZUTACD2hfuu1UFCKAUAUSgzU+rWTdqxQ9q4URo6NNwjAgLLSB3aRN2nBquWmqyf5OaOj67CHV9DpmjYpupPEOZ2tZWvAZGH1VkuVwVlSuc87LrOlru6af3n63hZgT778E2dde5YxTtupe2qv+T7HSNDhVVOAIBaEXTX6iAglAKAKGSxmKulXnvN3MJHKIWYY/GiMHjDVUse6yep6eLqDs0JmWJ9m2pzCut7Krjf8LPy9TP3UE/N6DJMpfGH1b/LsLrXu+vvaNu61PfPBACAoPPx3zBRKC7cAwAANI9jC9/69eEdBxA0jhU6SenO7UkZrgtD+9rfE0eIkTXZfIzRfwj6xN1n4mu7r+cPhRjdEhF6NX88ObZHOiRlSn1uN/+36E97q5ToPHdLec9Yux4+w8g+d4t5z2b8GybKWAzDaClVK5ulvLxcHTp00IEDB5ScnBzu4TSpqqpKK1as0Lhx45SQkBDu4SAKMYeiR2GhNGKElJEhFReHezR1mEPwh8v54+4OZO742h8xpVm/g6rt0r+yPGwXbck81AKTGt+90VMBfW/vJuipXQrquV1u/wzEucNxPWH6DGPqeprxnn7PoQi7nog+d4y+p8s5FIW8zVIIpZpAKIWWhjkUPQ4dkjp0kKqrpZISKT296deEAnMI/mD+wF/NnkPF+TXbP6WgFXSXQlgvys04mlMs3l3QJMVcAMzvIPiLOQR/xcoc8jZLoaYUAESpdu2kfv2kzz83t/DZYndVLwAEXygKukt1bU0W5/eTp3EEqhaYuzYAALxEKAUAUezcc81Q6sMPCaUAwG/BLujesM1jcX4fVzm5u1Ohu3F4KBZP0AQACBVCKQCIYoMHS3/9qxlKAQACwNewxp8Qx+3qrGaucgIAIMoQSgFAFKt/B75//MMsep6dLVn52wQAooOn1VkSq5kAADGNUAoAotjXX0sWi1RZKf3iF2ZbRoa0aBHb+QAgahAyAQBaqLhwDwAA0Dz5+dLll0sN76FaWipNmmQeBwAAAIBIRSgFAFHIbpdmzGgcSEl1bbm5Zj8AAAAAiESEUgAQhYqKpJIS98cNQyouNvsBAAAAQCQilAKAKFRWFth+AAAAABBqhFIAEIXS0gLbDwAAAABCjVAKAKJQdrZ5lz2LxfVxi0XKzDT7AQAAAEAkIpQCgChktUqLFpnPGwZTju8XLjT7AQAAAEAkIpQCgChls0l5eVJ6unN7SorZbrOFZ1wAAAAA4A1CKQCIYjabtHWrVFAgjRxptk2cSCAFAAAAIPLFh3sAAAD/WK3S8OHS4cPSmjXSihWSYbivNwUAAAAAkYCVUgAQI376U6lNG6m4WPryy3CPBgAAAAA8I5QCgBjRpo2Uk2M+f+ON8I4FAAAAAJpCKAUAMeTii83H118P7zgAAAAAoCmEUgAQQy66yHxcv17atSu8YwEAAAAATwilACCGpKdLZ59tFjp/881wjwYAAAAA3COUAoAY49jCR10pAAAAAJGMUAoAYowjlHrrLamyMrxjAQAAAAB3CKUAIMYMHCh16SIdPCgVFYV7NAAAAADgGqEUAMSYuLi6gud/+Yu0dKlUWCjZ7WEdFgAAAAA4IZQCgBiUmmo+Ll8uTZkijRghZWVJ+flhHRYAAAAA1CKUAoAYk58vLVjQuL20VJo0iWAKAAAAQGQglAKAGGK3SzNmSIbR+JijLTeXrXwAAAAAwo9QCgBiSFGRVFLi/rhhSMXFFEAHAAAAEH6EUgAQQ8rKAtsPAAAAAIKFUAoAYkhaWmD7AQAAAECwEEoBQAzJzpYyMiSLxfVxi0XKzDT7AQAAAEA4RU0otW/fPl111VVKTk5Wx44dNW3aNB06dMhj/1tuuUWnnXaa2rRpoxNPPFG33nqrDhw4EMJRA0BoWa3SokXmc3fB1MKFZj8AAAAACKdmhVLFxcUqqVdJd8OGDcrNzdVTTz0VsIE1dNVVV+nrr7/WqlWr9MYbb2jt2rW6/vrr3fbfvn27tm/froceekhfffWVnnvuOa1cuVLTpk0L2hgBIBLYbFJenpSe7tzepo3ZbrOFZ1wAAAAAUF+zQqkpU6aooKBAkrRjxw6NGjVKGzZs0O9//3vde++9AR2gJG3atEkrV67U008/rcGDB2vo0KFavHixXnrpJW3fvt3la8444wwtX75cl1xyiU4++WT99Kc/1QMPPKDXX39dx48fD/gYASCS2GzS1q1SQYH0pz+ZbZWV0tChYR0WAAAAANRqVij11VdfadCgQZKkV155RWeccYY++OADvfjii3ruuecCOT5J0rp169SxY0cNHDiwti0nJ0dxcXFav3691+c5cOCAkpOTFR8fH/AxAkCksVql4cOl3/5W+slPJLtd+sc/wj0qAAAAADA1K52pqqpSYmKiJGn16tX62c9+Jknq3bu3yoJwn/EdO3aoS5cuTm3x8fHq3LmzduzY4dU59uzZo/vuu8/jlj9JOnbsmI4dO1b7fXl5uSTzmquqqnwceeg5xhgNY0VkYg7FpmuuidNHH1n19NOGpk8/7rbeVCAwh+AP5g/8xRyCP5g/8BdzCP6KlTnk7fibFUqdfvrpevLJJ3XRRRdp1apVuu+++ySZdZxSUlK8Ps+dd96pPzn2lbixadOm5gzRSXl5uS666CL17dtX8+bN89h3/vz5uueeexq1v/3220pKSvJ7LKGyatWqcA8BUY45FFs6dYpXq1YXatMmqxYt+kCnnro/6O/JHII/mD/wF3MI/mD+wF/MIfgr2udQRUWFV/0shmEYvp68sLBQEyZMUHl5ua655ho988wzkqTf/e53+vbbb5Wfn+/VeXbv3q29e/d67HPSSSfpH//4h37zm9/oxx9/rG0/fvy4WrdurWXLlmnChAluX3/w4EGNGTNGSUlJeuONN9S6dWuP7+dqpVRmZqb27Nmj5ORkr64rnKqqqrRq1SqNGjVKCQkJ4R4OohBzKHZNnWrVkiVx+tWv7HriieqgvQ9zCP5g/sBfzCH4g/kDfzGH4K9YmUPl5eU64YQTassoudOslVLDhw/Xnj17VF5erk6dOtW2X3/99T6tJkpNTVVqamqT/c477zzt379fn3zyiQYMGCBJeuedd1RdXa3Bgwe7fV15ebnGjBmjxMRE/etf/2oykJKkxMTE2q2J9SUkJETVhIi28SLyMIdiz69+JS1ZIr30klUTJ1r1449SWpqUnW3Wnwo05hD8wfyBv5hD8AfzB/5iDsFf0T6HvB17swqdHzlyRMeOHasNpH744QctXLhQmzdvblT7KRD69OmjCy+8UNddd502bNig999/X9OnT9eVV16p7t27S5JKS0vVu3dvbdiwQZIZSI0ePVqHDx/W3//+d5WXl2vHjh3asWOH7HZ7wMcIAJFu2DCpSxfp0CFp7FhpyhRpxAgpK0vycoErAAAAAARMs0Kp8ePH64UXXpAk7d+/X4MHD9bDDz+sSy+9VH/5y18COkCHF198Ub1799bIkSM1btw4DR06VE899VTt8aqqKm3evLl23+LGjRu1fv16ffnllzrllFOUlpZW+1VcXByUMQJAJHvtNWnXrsbtpaXSpEkEUwAAAABCq1nb9zZu3KhHH31UkpSXl6euXbvq008/1fLlyzVnzhz9+te/DuggJalz585asmSJ2+NZWVmqXx5r+PDhaka5LACISXa7NGOG62OGIVksUm6uNH58cLbyAQAAAEBDzVopVVFRofbt20sy70pns9kUFxenc889Vz/88ENABwgA8F9RkVRS4v64YUjFxWY/AAAAAAiFZoVSp5xyil577TUVFxfrrbfe0ujRoyVJu3btioo71AFAS1NWFth+AAAAAOCvZoVSc+bM0W233aasrCwNGjRI5513niRz1dTZZ58d0AECAPyXlhbYfgAAAADgr2bVlJo0aZKGDh2qsrIy9e/fv7Z95MiRmjBhQsAGBwAIjOxsKSPDLGruqtyexWIez84O/dgAAAAAtEzNCqUkqVu3burWrZtKaoqUZGRkaNCgQQEbGAAgcKxWadEi8y57FovrYGrhQoqcAwAAAAidZm3fq66u1r333qsOHTqoR48e6tGjhzp27Kj77rtP1dXVgR4jACAAbDYpL09KT3duT0oy22228IwLAAAAQMvUrJVSv//97/X3v/9df/zjHzVkyBBJ0nvvvad58+bp6NGjeuCBBwI6SABAYNhs0vjx5l323n9fmj1bqqyUzj8/3CMDAAAA0NI0K5R6/vnn9fTTT+tnP/tZbduZZ56p9PR03XTTTYRSABDBrFZp+HDz69//ltatk556SpozJ9wjAwAAANCSNGv73r59+9S7d+9G7b1799a+ffv8HhQAIDRuucV8fPJJc8UUAAAAAIRKs0Kp/v3767HHHmvU/thjj+nMM8/0e1AAgNCYOFHq1k0qK5Puv19aulQqLJTs9nCPDAAAAECsa9b2vQcffFAXXXSRVq9erfPOO0+StG7dOhUXF2vFihUBHSAAIHhatZIuuEB65RXpvvvq2jMyzLv1UfwcAAAAQLA0a6XUsGHD9N1332nChAnav3+/9u/fL5vNpq+//lr/93//F+gxAgCCJD9fWrascXtpqTRpknkcAAAAAIKhWSulJKl79+6NCpp//vnn+vvf/66nnnrK74EBAILLbpdmzJAMo/Exw5AsFik317xbn9Ua8uEBAAAAiHHNWikFAIh+RUVSSYn744YhFReb/QAAAAAg0AilAKCFKisLbD8AAAAA8AWhFAC0UGlpge0HAAAAAL7wqaaUrYnbMO3fv9+fsQAAQig727zLXmmp67pSFot5PDs79GMDAAAAEPt8CqU6dOjQ5PGrr77arwEBAELDapUWLTLvsmexuA6mFi6kyDkAAACA4PAplHr22WeDNQ4AQBjYbFJennkXvoZFz++91zwOAAAAAMFATSkAaOFsNmnrVqmgQFqyRLroIrP900/DOiwAAAAAMc6nlVIAgNhktUrDh5vP+/eX/v1v6bXXpC1bpJ49wzkyAAAAALGKlVIAACd9+0pjxkjV1dKf/xzu0QAAAACIVYRSAIBGZs40H//+d6m8PLxjAQAAABCbCKUAAI2MHi316SMdPCjddZe0dKlUWCjZ7eEeGQAAAIBYQSgFAGjEYpEuuMB8/sQT0pQp0ogRUlaWlJ8f1qEBAAAAiBGEUgCARvLzpaeeatxeWipNmkQwBQAAAMB/hFIAACd2uzRjhmQYjY852nJz2coHAAAAwD+EUgAAJ0VFUkmJ++OGIRUXm/0AAAAAoLkIpQAATsrKAtsPAAAAAFwhlAIAOElLC2w/AAAAAHCFUAoA4CQ7W8rIMO/A54rFImVmmv0AAAAAoLkIpQAATqxWadEi87mrYMowpIULzX4AAAAA0FyEUgCARmw2KS9PSk9vfKxHD+nSS0M+JAAAAAAxhlAKAOCSzSZt3SoVFEhLlkj//KfUvr30ww9mYAUAAAAA/ogP9wAAAJHLapWGD6/7/rbbpLlzpbvvllJSpF27zILn2dls5wMAAADgG1ZKAQC8lpsrtWsnffedlJMjTZkijRghZWVJ+fnhHh0AAACAaEIoBQDw2urV0qFDjdtLS6VJkwimAAAAAHiPUAoA4BW7XZoxw/UxwzAfc3PNfgAAAADQFEIpAIBXioqkkhL3xw1DKi6W3nvPErpBAQAAAIhahFIAAK+UlQW2HwAAAICWjVAKAOCVtLTA9gMAAADQshFKAQC8kp0tZWRIFg+78zIypOpqae3adL37roX6UgAAAADcIpQCAHjFapUWLTKfuwumDh6UxoyJ1yOPDNSoUfHKyuKOfAAAAABcI5QCAHjNZpPy8qT0dOf2Vq3MxwMHnNtLS6VJkwimAAAAADRGKAUA8InNJm3dKhUUSEuWSKtXSyec4LqvYZiPubliKx8AAAAAJ4RSAACfWa3S8OHS5Mnm8+3b3fc1DKm4WCoqCtnwAAAAAEQBQikAgF/KygLbDwAAAEDLQCgFAPBLWlpg+wEAAABoGQilAAB+yc6WMjLc35HPYpEyM81+AAAAAOBAKAUA8IvVKi1aZD53F0wtXGj2AwAAAAAHQikAgN9sNikvT0pPb3zsxhvN4wAAAABQX3y4BwAAiA02mzR+vFRQcFxvvvmZDh8+W3/9q1XLl0sXXywdOGDWlcrOZtUUAAAAAEIpAEAAWa3SsGGGDh8uVU5Of/3zn1bt2CFddFFdn4wMc7sfq6cAAACAlo3tewCAoPj3vy3asaNxe2mpNGmSlJ8f+jEBAAAAiByEUgCAgLPbpVmzXO/RMwzzMTfX7AcAAACgZSKUAgAE3DffpKi01M2t+GQGU8XFUlFRCAcFAAAAIKIQSgEAAu7HH1t71a+sLMgDAQAAABCxCKUAAAHXqdNRr/qlpQV5IAAAAAAiFqEUACDg+vbdq/R0QxY3O/gsFikzU8rODu24AAAAAEQOQikAQMBZrdIjj5hVzF0FU4YhLVxo9gMAAADQMhFKAQCCYsIEQ3l5Unp642OJidK554Z+TAAAAAAiB6EUACBobDZp61apoEBaskR65x1p8GDp2DHpd7+TCgulpUvNR7s9zIMFAAAAEFLx4R4AACC2Wa3S8OF13y9cKJ13nvT88+aXQ0aGtGiRGWQBAAAAiH2slAIAhNT27a7bS0ulSZOk/PzQjgcAAABAeBBKAQBCxm6XZsxwfcwwzMfcXLbyAQAAAC0BoRQAIGSKiqSSEvfHDUMqLjb7AQAAAIhthFIAgJApKwtsPwAAAADRi1AKABAyaWne9du5k7vyAQAAALGOu+8BAEImO9u8y15paV0NqYbi4qSZM+u+5658AAAAQGxipRQAIGSsVjNgkiSLxXWf6mrn77krHwAAABCbCKUAACFls0l5eVJ6unN7nJv/R+KufAAAAEBsIpQCAISczSZt3SoVFEhLlkiPPtp4hVR93JUPAAAAiD3UlAIAhIXVKg0fbj5futS713BXPgAAACB2sFIKABB23JUPAAAAaHlYKQUACDvuygcAAAC0PKyUAgCEHXflAwAAAFoeQikAQETgrnwAAABAy0IoBQCIGNyVDwAAAGg5qCkFAIgo3JUPAAAAaBlYKQUAiFje3pXP234AAAAAIgehFAAgYjnuyueu+LnFImVmmv0AAAAARBdCKQBAxGrqrnyGIT38sFlTaulSqbCQoucAAABAtCCUAgBENHd35XO48UZpxAhpyhTzMStLys8P6RABAAAANAOhFAAg4jW8K19BgTRxonls3z7nvqWl0qRJBFMAAABApOPuewCAqFD/rnx2u/SLX7juZxjmVr/cXGn8ePN1AAAAACIPK6UAAFGnqEgqKXF/3DCk4mKzHwAAAIDIRCgFAIg6ZWWB7QcAAAAg9KImlNq3b5+uuuoqJScnq2PHjpo2bZoOHTrk1WsNw9DYsWNlsVj02muvBXegAICgS0sLbD8AAAAAoRc1odRVV12lr7/+WqtWrdIbb7yhtWvX6vrrr/fqtQsXLpTF1b3EAQBRKTtbysgwa0e5k5pqFj0vLDRrUAEAAACILFERSm3atEkrV67U008/rcGDB2vo0KFavHixXnrpJW3fvt3jaz/77DM9/PDDeuaZZ0I0WgBAsFmt0qJF5nN3wdTu3dLPfy6NGCFlZXE3PgAAACDSRMXd99atW6eOHTtq4MCBtW05OTmKi4vT+vXrNWHCBJevq6io0JQpU/T444+rW7duXr3XsWPHdOzYsdrvy8vLJUlVVVWqqqry4ypCwzHGaBgrIhNzCP4K1Ry65BLppZcsmjXLqtLS+smUIck5qSotNTRpkvTSS3ZNmGAEdVzwD7+D4C/mEPzB/IG/mEPwV6zMIW/HHxWh1I4dO9SlSxentvj4eHXu3Fk7duxw+7qZM2fq/PPP1/jx471+r/nz5+uee+5p1P72228rKSnJ+0GH2apVq8I9BEQ55hD8FYo5lJgo/fnP0jffpGjv3tZ65pl+Ki9v1aifYVgkGbr55krFx6+S1Rr0ocFP/A6Cv5hD8AfzB/5iDsFf0T6HKioqvOoX1lDqzjvv1J/+9CePfTZt2tSsc//rX//SO++8o08//dSn1911112aNWtW7ffl5eXKzMzU6NGjlZyc3KyxhFJVVZVWrVqlUaNGKSEhIdzDQRRiDsFf4ZhDl1wivfuuRQsXevq/NYv27EnSli0Xq0sXQ2lp0tChBgFVhOF3EPzFHII/mD/wF3MI/oqVOeTYddaUsIZSv/nNbzR16lSPfU466SR169ZNu3btcmo/fvy49u3b53Zb3jvvvKP//ve/6tixo1P7xIkTlZ2drcLCQpevS0xMVGJiYqP2hISEqJoQ0TZeRB7mEPwV6jm0e7d3/W67rS6Fysgwa1PZbEEaFJqN30HwF3MI/mD+wF/MIfgr2ueQt2MPayiVmpqq1NTUJvudd9552r9/vz755BMNGDBAkhk6VVdXa/DgwS5fc+edd+pXv/qVU1u/fv306KOP6pJLLvF/8ACAiJKW5vtrSkulSZOkvDyCKQAAACDUouLue3369NGFF16o6667Ths2bND777+v6dOn68orr1T37t0lSaWlperdu7c2bNggSerWrZvOOOMMpy9JOvHEE9WzZ8+wXQsAIDiys82VT+7uxueKUVPzPDdXstuDMiwAAAAAbkRFKCVJL774onr37q2RI0dq3LhxGjp0qJ566qna41VVVdq8ebPXxbQAALHFajW34km+B1PFxdLixdLSpVJhIQEVAAAAEApRcfc9SercubOWLFni9nhWVpYMw/Ntvps6DgCIbjabuRVvxgyppMS3186cWfecWlMAAABA8EXNSikAALxhs0lbt0oFBdKSJdKjj/p+Dketqfz8gA8PAAAAQI2oWSkFAIC3rFZp+HDzud0uPfywGTR5u2DWMMwtgLm50vjx5vkAAAAABBYrpQAAMY1aUwAAAEBkIpQCAMQ8R62p9HTfXztzpjRlijRihJSVxZY+AAAAIFAIpQAALQK1pgAAAIDIQk0pAECLQa0pAAAAIHKwUgoA0CL5W2uqqCg44wIAAABaCkIpAECL5U+tqbKywI8HAAAAaEkIpQAALVpza02lpQV1WAAAAEDMo6YUAKDF87XWVGqqebywUMrOprYUAAAA0ByslAIAoB5vak3t3i39/OfSiBFSVhZ34wMAAACag1AKAIAGfKk1VVoqTZpEMAUAAAD4ilAKAAAX6tea+sc/zC17rji2+OXmmlv/AAAAAHiHmlIAALjhqDVVWGhu2XPHMKTiYmnxYqlrV7MIOrWmAAAAAM8IpQAAaEJZmXf9Zs6se56RYdamstmCMyYAAAAg2rF9DwCAJqSl+f4aak0BAAAAnrFSCgCAJmRnmyufSkvrakg1xTDMu/fNmCF16CDt2sW2PgAAAKA+VkoBANAEq9XciieZQZO3DEMqKZFycqQpU6QRI6SsLFZPAQAAABKhFAAAXrHZpLw8KT3dv/OwrQ8AAAAwEUoBAOAlm03aulUqKJCWLJEefdT3czi2/+XmSnZ7IEcHAAAARBdqSgEA4AOrVRo+3Hxut0sPP+xbrSnJ7FtcLBUV1Z0LAAAAaGlYKQUAQDM1t9aUQ1lZYMcDAAAARBNCKQAA/OBPram0tMCPBwAAAIgWhFIAAPipYa2p1auljAz3q6csFikzU8rODukwAQAAgIhCTSkAAAKgfq0pydzWN2mSGUA1rDdlGNKDD5o1pcrKzBVT2dnmOQAAAICWgpVSAAAEgbttfY7VU9dfL40YIU2ZYj5mZUn5+SEfJgAAABA2hFIAAARJw219BQVSbq557OBB576lpebKKoIpAAAAtBRs3wMAIIjqb+uz26Vf/MJ1P8MwV1HNmCF16CDt2sW2PgAAAMQ2QikAAEKkqEgqKXF/3DDM4zk5dW0ZGWZ9Kpst+OMDAAAAQontewAAhEhZme+vYVsfAAAAYhWhFAAAIZKW5vtrHHfuy801t/8BAAAAsYJQCgCAEMnONrfjOe7A5y3DkIqLpXnzpMJCwikAAADEBkIpAABCxGo160NJvgdTknT//dKIEVJWFtv5AAAAEP0IpQAACCGbTcrLk9LTm38O6kwBAAAgFnD3PQAAQsxmk8aPN+/GV1YmdekiTZ1qhk2OGlKeGIa50mrGDKlDB2nXLrNeVXa2uRoLAAAAiAaEUgAAhIHVKg0fXvf9okXm6ieLxftgqqREysmpa8vIMM9jswV8uAAAAEDAsX0PAIAIEIptfXa7WSh96VIKpgMAACD8CKUAAIgQNpu0datUUCDNnu376x0rrHJzGwdO+flmgfQRI6QpUyiYDgAAgPAjlAIAIII4tvXNm2dux/P1Ln2GIRUXm/WqHPLzzRVUJSXOfSmYDgAAgHAilAIAIAJZrWZ9KMn3YEqS1qwxt+mtWWMWRHdVp8rTyioAAAAg2Ch0DgBAhHLUmZoxo/Eqp6bcf793/eqvrKpfeB0AAAAINlZKAQAQwerXmVqyRFq9unnb+ppSVhbY8wEAAABNYaUUAAARzlFnymHRIrMWlMXieltec+zcaW73S0uTsrPN9wQAAACCiZVSAABEGce2vvT0wJzPapVmzuSufAAAAAgtQikAAKJQw219s2c3/1wNi5xzVz4AAACEAqEUAABRyrGtb/JkaeRI318f5+ZfAdyVDwAAAKFAKAUAQAzIzvZcAN1iMY+vXm2urHr0Uam62v356t+VDwAAAAgGQikAAGKA1WoWQJcaB1OO7xctMldUTZ4sde3q3XmXL5cKC1kxBQAAgMAjlAIAIEa4K4CekWG222x1bWlp3p3zsccofg4AAIDgiA/3AAAAQODYbNL48ea2u7IyM3zKzjZXUtXn2O5XWlpXQ8oTR/HzhuEWAAAA0FyEUgAAxBhHAfSm+ixaZAZNFkvTwZRhmP1mzJA6dJB27XIfeAEAAADeYPseAAAtlLvtfu4YhlRSIuXkSFOmsK0PAAAA/iGUAgCgBbPZpK1bpYICafp031/v2NZHMAUAAABfEUoBANDCObb7TZzo+2sd2/5yc7lDHwAAAHxDTSkAACDJ9+LnDoYhFRdLixdLXbtSawoAAADeIZQCAACSfC9+3tDMmXXPMzLMc3lzJ0AAAAC0TIRSAACglqP4+YwZZlHz5iotNbcDpqRIe/fWtWdkSI88IqWmElQBAAC0dIRSAADAic3mvMKpSxdp6lTftvU5+tUPpCQz6Lr8cuc2x6oqm83voQMAACCKUOgcAAA04ih+PnmyNHKkGRpJ5ra+QOMOfgAAAC0ToRQAAGiSY1tfenrgz80d/AAAAFomQikAAOAVm03aulUqKJCWLJEefTRw53bcwe+994KwFAsAAAARiZpSAADAa45tfZK5qunhh32rNdWUd96x6NixdLVta9GIEeb72e3cwQ8AACAWEUoBAIBmsVrNWlOTJpm1pgIRTM2fb5U0UI88YhZAnzxZWrrU+U6AFEYHAACIDWzfAwAAzeau1lRKivnoT2H0khJpwQLnQEqiMDoAAECsIJQCAAB+aVhrqqBA2rlTWr6cwugAAABwj+17AADAb/VrTTnYbNL48c71oPbskWbObLz6yVeOwuhFRY3fFwAAANGBUAoAAASNq7BqwoS6oOqbb6T772/++cvK/BoeAAAAwojtewAAIKQcQdXkydLIkf6dKy0tIEMCAABAGBBKAQCAsMnONu+m15yC6BkZZk2ppUulwkLqSwEAAEQbtu8BAICwsVqlRYvMu+lZLHVFzL1x+LCUk1P3fUaGea6Gdayys833AQAAQGRhpRQAAAgrm03Ky2t8p77MTOn2282wqT5HwPTjj87tpaXSxIlS167SiBHSlCnmY1aWlJ8ftOEDAACgmVgpBQAAws5xp76CguN6883PNHbsWRoxIl5WqzR/ft3Kpy5dpJ//XNqxo/E5HKus9u51bneEVffcI/Xq5bx6ym5nVRUAAEC4EEoBAICIYLVKw4YZOny4VMOG9a8Nh+rfwa+w0HUg5YkjrJo7t64tI8MstL50qVRS4tzOFkAAAIDQIJQCAABRo6wsMOcpKZEWLGjc7lhVlZLivOLKEVbZbIF5fwAAAFBTCgAARJG0tOCe39MWwEmTqE0FAAAQSIRSAAAgamRnm6uWLJbQvq8jrMrNNetQAQAAwH+EUgAAIGpYreY2Oik8wVRxsVlrqiG73ax3tXSp+UhwBQAA0DRCKQAAEFVsNikvT0pPd25PSTEfgx1WNaxrlZ8vZWVJI0ZIU6aYj1lZbPUDAABoCqEUAACIOjabtHWrVFAgLVliPu7cKS1f3jisCrSdO+tWROXlmbWm6t/BT6IGFQAAgDe4+x4AAIhKVqs0fLhzm80mjR9vbrErK5O+/16aN8885qgL5Y+4OGnmTOcxuDqvYZgrtnJzzfFYrf6/NwAAQKxhpRQAAIgpjrBq8mRpzhzXW/0yM6XbbzeLptfX1BbA6mrn7z3VjvJUgwoAAACslAIAADGu4eqptDTzLn5WqzR/fuP2f/5TmjHDeUteXFzjQMpby5ebj473BAAAgIlQCgAAxDxXW/3ctTcMsXbudN6y56vHHjO/MjLMOwfabM0/FwAAQCwhlAIAAGigfli1dGlgzukofv7yy1JqauNVW3a769VcAAAAsYpQCgAAwIO0tMCcx1EQffJk51pUGRlm29KlzlsGWVkFAABiHaEUAACAB9nZZkBUWur+Dn6OlU7eaNivpERasKBxv6ZWVgEAAES7qLn73r59+3TVVVcpOTlZHTt21LRp03To0KEmX7du3Tr99Kc/Vdu2bZWcnKwLLrhAR44cCcGIAQBALLBazRVLUuO78lks5tfSpVJBgTR9euDe1zDMr8mTpREjpClTzMesLCk/P3DvAwAAEC5RE0pdddVV+vrrr7Vq1Sq98cYbWrt2ra6//nqPr1m3bp0uvPBCjR49Whs2bNBHH32k6dOnKy4uai4bAABEAJtNysuT0tOd2zMyzPbLLjNrUE2cGPj3briyyrGCimAKAABEu6jYvrdp0yatXLlSH330kQYOHChJWrx4scaNG6eHHnpI3bt3d/m6mTNn6tZbb9Wdd95Z23baaaeFZMwAACC2NLwrn6utdN5s9fOXYZirs3JzzfGwlQ8AAESrqAil1q1bp44dO9YGUpKUk5OjuLg4rV+/XhMmTGj0ml27dmn9+vW66qqrdP755+u///2vevfurQceeEBDhw51+17Hjh3TsWPHar8vLy+XJFVVVamqqiqAVxUcjjFGw1gRmZhD8BdzCP6IhvkzZEjd8+pq86u+hx+26MorrbJYJMNosN8vQAxDKi6WCgqOa9iwIKVfUSoa5hAiF/MH/mIOwV+xMoe8HX9UhFI7duxQly5dnNri4+PVuXNn7dixw+Vr/ve//0mS5s2bp4ceekhnnXWWXnjhBY0cOVJfffWVevXq5fJ18+fP1z333NOo/e2331ZSUpKfVxI6q1atCvcQEOWYQ/AXcwj+iOb5k5go/fa3aXr66X7au7dNbXtcXLWqqy2SXAVVhpt2z9588zMdPlza7LHGsmieQwg/5g/8xRyCv6J9DlVUVHjVL6yh1J133qk//elPHvts2rSpWeeurvnPljfccIOuvfZaSdLZZ5+tNWvW6JlnntH8+fNdvu6uu+7SrFmzar8vLy9XZmamRo8ereTk5GaNJZSqqqq0atUqjRo1SgkJCeEeDqIQcwj+Yg7BH7Eyf8aNk+bNk95773jtVr89e6QpU6ySjAYrqIx6j74FU4mJZ6tt27M0dKjBNr4asTKHEB7MH/iLOQR/xcoccuw6a0pYQ6nf/OY3mjp1qsc+J510krp166Zdu3Y5tR8/flz79u1Tt27dXL4uLS1NktS3b1+n9j59+mjbtm1u3y8xMVGJiYmN2hMSEqJqQkTbeBF5mEPwF3MI/oiF+ZOQIOXkOLe1aiXNmCGVlNS1ZWZadOWV5h386rdbrY2LnDc0f75V8+ebdawWLTLrXsEUC3MI4cP8gb+YQ/BXtM8hb8ce1lAqNTVVqampTfY777zztH//fn3yyScaMGCAJOmdd95RdXW1Bg8e7PI1WVlZ6t69uzZv3uzU/t1332ns2LH+Dx4AAMBHnoqlz5/v3L5nj3T55ebrmiqa7rgjX14ewRQAAIgeUVFTqk+fPrrwwgt13XXX6cknn1RVVZWmT5+uK6+8svbOe6WlpRo5cqReeOEFDRo0SBaLRbfffrvmzp2r/v3766yzztLzzz+vb7/9Vnl5eWG+IgAA0FJZrdLw4d615+U1XlnlCnfkAwAA0SgqQilJevHFFzV9+nSNHDlScXFxmjhxov785z/XHq+qqtLmzZudimnl5ubq6NGjmjlzpvbt26f+/ftr1apVOvnkk8NxCQAAAD6pv7JqzRrp/vvd93Xcka+oyHXoBQAAEGmiJpTq3LmzlixZ4vZ4VlaWDBdr2++8807deeedwRwaAABA0DhWUJWVedff234AAADhFhfuAQAAAKBpNfdwadLOnWbR9MLCpgulAwAAhFPUrJQCAABoybKzzbvslZa6L3weFyfNnFn3PXflAwAAkYyVUgAAAFHAajUDJsksau5KdbXz94678uXnB3dsAAAAzUEoBQAAECVsNvOOfOnpzu1xbv5F51hRlZvLVj4AABB5CKUAAACiiM0mbd0qFRRIS5ZIjz7aeIVUffXvygcAABBJqCkFAAAQZRx35JPMoube4K58AAAg0rBSCgAAIIp5e1c+b/sBAACECqEUAABAFHPclc9d8XOLRcrMNPsBAABEEkIpAACAKNbUXfkMQ1q40OwHAAAQSQilAAAAopy7u/JJUps20pAhoR8TAABAUwilAAAAYkDDu/KtXi2dc4505Ij0299KhYVmUfTCQsluD/NgAQAAxN33AAAAYkb9u/JJ0hNPSOeeK73wgvnlkJFhbvmz2UI+RAAAgFqEUgAAADGqtNR9+6RJ0ssvS6mpUlmZeXe+7GxqTwEAgNAhlAIAAIhBdrs0Y4brY4ZhPk6e7LyVz7GCavx4qaiIsAoAAAQXoRQAAEAMKiqSSko892lYW6q0VJo4UUpJkfburWtnux8AAAgGQikAAIAYVFbm+2scK6jqB1JSXVh1zz1Sr16sngIAAIFBKAUAABCD0tICdy5HWDV3bl0bq6cAAIC/CKUAAABiUHa2GRyVltaFSoFEsXQAAOAvQikAAIAYZLWaK5kmTZIslsAHU4Eulm63U1wdAICWJi7cAwAAAEBw2GxSXp6Unu7cHsiwx12x9K5dpREjpClTzMesLCk/3/U58vPN4972BwAAsYGVUgAAADHMZmu8amnPHunyy83jwVpB5apYuqvtfo6xNByHo39eHnWrAACIVYRSAAAAMc5qlYYPd27Ly5NmzJBKSuraUlLMMCmU2/2sVtfvZRjmOHJzzVCNrXwAAMQetu8BAAC0QDabtHWrVFAgLVliPu7cKS1f3ni7XyA13O7X8Pv6DEMqLjZXeQEAgNjDSikAAIAWytUKqobb/b7/Xpo3zzwWjLv4eaOsLDzvCwAAgotQCgAAAE4ahlVnnNF4q5/V6nmVUyB9841UWOjdHfzefdeitWvT1batRSNG+L7tj7sAAgAQOmzfAwAAgEeutvq99JJZ88liCf7733+/93fwGzUqXo88MlCjRsX7fAc/7gIIAEBosVIKAAAATYqEYunu7siXn2+2u7uDX8M7/rla/RSIc0SiQK38YgUZACAYCKUAAADQLA3rTznCin/+0/ftft5sB3TckW/GDKlDB2nXLqlLF/N7d3fwkxrf8S8jQ1q0qC7Ystv9P4c/3AU+/gZB+fmNfw6Ocbv6ubk7t7vzPPKI66DO1+vxpV0KzmcFAAgPQikAAAA0mzfF0tPSpD17pMsvN4/XD38c2/+WLjUDjjVrzO167hiGGY7k5Hg/xoZhV8MVV0VFzoGLL+fwdwWVu8Bn8mTzM2luoORp5dfEiXUr2po6t+Pn1vA8JSV1P09vxh2I9pQU87HhuJvzWbkLvFzVJIukkC3S3zPWrqc57+nvHIq064nkc8fqe/pbGzHqGPDowIEDhiTjwIED4R6KVyorK43XXnvNqKysDPdQEKWYQ/AXcwj+YP7EtuXLDSMjwzDMiMP8ysw02x2WLHE+Hsyv1FTD+Mc/DGP27Oafw2p1/j4jw7ye48cNo6DAvJ6CAvN7V5+HxeL9ezn6pqQ0fs9XXql7v9WrG3/OzT13w+uLli9Pn9Xttzf+fFJSvO8bqPZYe89Yux4+w8g+d0t6z/r/HxlNvM1SLIZhGOEOxiJZeXm5OnTooAMHDig5OTncw2lSVVWVVqxYoXHjxikhISHcw0EUYg7BX8wh+IP5E/ua2mZVWGgWGI9Wjlpa7lYi1d8ymJXV9AotAEDL5VhN3LCWYjTwNkth+x4AAABCxtV2v/qys80Ap7TUDHeijWPM9QMpqW7b3D33SL16STt3EkgBADwzDDOYys01tyPH4lY+QikAAABEDKvVXFE0aVJw7uAXLo7rmDs3vOMAAEQXw5CKi81Vxp7+o060igv3AAAAAID6bDZzq0J6un/nCcR/UY7F/yoNAIg+ZWXhHkFwsFIKAAAAEafhHfy6dJGmTnW/rc9iMUOsv//9uN566zONHXuW9u+Pd3nHv6bMni317ev5roEAAIRSWlq4RxAchFIAAACISA3rT7nb1ucoBLtokTRihKEjR0o1bFh/JSSYK65mzPCtftPIkc7v6+ocjlt3RxtHAXZft0ZG6/UCQLSzWMxai9nZ4R5JcLB9DwAAAFHB3ba+jAz3dyay2aStW6WCAukf/5BSU+tCrIYsFikzs/E//OufY8kS8/Gll8z+7s7lj8xM6fbbzeuqLyWlbpzecPwhs3p13bh37pSWL2/8Gbo7t+Maly51vv5lyxqPz924A9WeklI3Tm/6uroeAIgmjt9hCxfG8HZyAx4dOHDAkGQcOHAg3EPxSmVlpfHaa68ZlZWV4R4KohRzCP5iDsEfzB944/hxwygoMIwlS8zH48frjjU1h5YvNwyLxfwy1wqZX4625cu9H8fy5YaRkeF8npSUuvPVb2/q69FHG1+Pq+t09Z6uvpq6Hm/PnZnp2zmC3e5LX3fXc/vtrn9ujp9dU30D1R5r7xlr18NnGNnnbknv6cv/L0USb7MUi2EYRriDsUhWXl6uDh066MCBA0pOTg73cJpUVVWlFStWaNy4cUpISAj3cBCFmEPwF3MI/mD+wF/ezKH8/Mbb8TIzzf8S7Wq1lSd2e13dq7Q0c5XVP//p/ZZBx2qmLVu8/6/gDd9zzx5p5szgXU80/9d5d9fjql2SCgqO6803zZpkI0bEu+0bqHYpeOcOx3vG2vU05z39nUORdj2RfO5YfU9XcygaeZulEEo1gVAKLQ1zCP5iDsEfzB/4y9s5FOzwpf75v/9emjfPbK//L2/Htgx3Ww+b+36xECaFC7+D4C/mEPwVK3PI2yyFQucAAABocRoWUQ/2+c84o/HqqYyM5q1m8ub9AACIBoRSAAAAQJDZbNL48axmAgCgPkIpAAAAIARYzQQAgLO4cA8AAAAAAAAALQ+hFAAAAAAAAEKOUAoAAAAAAAAhRygFAAAAAACAkCOUAgAAAAAAQMgRSgEAAAAAACDkCKUAAAAAAAAQcoRSAAAAAAAACDlCKQAAAAAAAIQcoRQAAAAAAABCjlAKAAAAAAAAIUcoBQAAAAAAgJAjlAIAAAAAAEDIEUoBAAAAAAAg5AilAAAAAAAAEHLx4R5ApDMMQ5JUXl4e5pF4p6qqShUVFSovL1dCQkK4h4MoxByCv5hD8AfzB/5iDsEfzB/4izkEf8XKHHJkKI5MxR1CqSYcPHhQkpSZmRnmkQAAAAAAAESPgwcPqkOHDm6PW4ymYqsWrrq6Wtu3b1f79u1lsVjCPZwmlZeXKzMzU8XFxUpOTg73cBCFmEPwF3MI/mD+wF/MIfiD+QN/MYfgr1iZQ4Zh6ODBg+revbvi4txXjmKlVBPi4uKUkZER7mH4LDk5OaonMMKPOQR/MYfgD+YP/MUcgj+YP/AXcwj+ioU55GmFlAOFzgEAAAAAABByhFIAAAAAAAAIOUKpGJOYmKi5c+cqMTEx3ENBlGIOwV/MIfiD+QN/MYfgD+YP/MUcgr9a2hyi0DkAAAAAAABCjpVSAAAAAAAACDlCKQAAAAAAAIQcoRQAAAAAAABCjlAqxjz++OPKyspS69atNXjwYG3YsCHcQ0IEmj9/vn7yk5+offv26tKliy699FJt3rzZqc/w4cNlsVicvm688cYwjRiRZt68eY3mR+/evWuPHz16VDfffLNSUlLUrl07TZw4UTt37gzjiBFpsrKyGs0hi8Wim2++WRK/g+Bs7dq1uuSSS9S9e3dZLBa99tprTscNw9CcOXOUlpamNm3aKCcnR99//71Tn3379umqq65ScnKyOnbsqGnTpunQoUMhvAqEk6c5VFVVpTvuuEP9+vVT27Zt1b17d1199dXavn270zlc/d764x//GOIrQTg09Tto6tSpjebGhRde6NSH30EtW1NzyNW/iSwWixYsWFDbJ1Z/BxFKxZCXX35Zs2bN0ty5c7Vx40b1799fY8aM0a5du8I9NESYd999VzfffLM+/PBDrVq1SlVVVRo9erQOHz7s1O+6665TWVlZ7deDDz4YphEjEp1++ulO8+O9996rPTZz5ky9/vrrWrZsmd59911t375dNpstjKNFpPnoo4+c5s+qVaskSZdddlltH34HweHw4cPq37+/Hn/8cZfHH3zwQf35z3/Wk08+qfXr16tt27YaM2aMjh49Wtvnqquu0tdff61Vq1bpjTfe0Nq1a3X99deH6hIQZp7mUEVFhTZu3Ki7775bGzduVH5+vjZv3qyf/exnjfree++9Tr+XbrnlllAMH2HW1O8gSbrwwgud5sbSpUudjvM7qGVrag7VnztlZWV65plnZLFYNHHiRKd+Mfk7yEDMGDRokHHzzTfXfm+3243u3bsb8+fPD+OoEA127dplSDLefffd2rZhw4YZM2bMCN+gENHmzp1r9O/f3+Wx/fv3GwkJCcayZctq2zZt2mRIMtatWxeiESLazJgxwzj55JON6upqwzD4HQT3JBmvvvpq7ffV1dVGt27djAULFtS27d+/30hMTDSWLl1qGIZhfPPNN4Yk46OPPqrt8+abbxoWi8UoLS0N2dgRGRrOIVc2bNhgSDJ++OGH2rYePXoYjz76aHAHh4jnav5cc801xvjx492+ht9BqM+b30Hjx483fvrTnzq1xervIFZKxYjKykp98sknysnJqW2Li4tTTk6O1q1bF8aRIRocOHBAktS5c2en9hdffFEnnHCCzjjjDN11112qqKgIx/AQob7//nt1795dJ510kq666ipt27ZNkvTJJ5+oqqrK6fdR7969deKJJ/L7CC5VVlbqH//4h375y1/KYrHUtvM7CN7YsmWLduzY4fQ7p0OHDho8eHDt75x169apY8eOGjhwYG2fnJwcxcXFaf369SEfMyLfgQMHZLFY1LFjR6f2P/7xj0pJSdHZZ5+tBQsW6Pjx4+EZICJO4f+3d/8xVdV/HMdfV+BeLgjEhbj3YpNQjFGJm5jILDdjS7C5aTiFqF2YaSZQyiwWiynL1V9ZW1vUGmJbWYuW5uyHC8StGVqzIbopC2ZaAyxxlFCUej/fP5z3+71hqN/luVd4Pra7nfv5nHN5f7az9zl7cz6fs3+/UlJSlJmZqaeeekoDAwOBPnIQbsSZM2f06aefatWqVaP6xmMOigx1APh3nD17VpcuXZLb7Q5qd7vdOnHiRIiiwq3A7/dr/fr1mj9/vu69995A+6OPPqq0tDSlpqaqs7NTNTU16urq0scffxzCaBEucnNztX37dmVmZqqvr0/19fV64IEHdOzYMfX398tut4+6kXe73erv7w9NwAhru3bt0uDgoMrKygJt5CBcryt55Wr3QFf6+vv7lZKSEtQfGRkpl8tFXsIoIyMjqqmpUUlJieLj4wPtTz/9tGbPni2Xy6Wvv/5azz//vPr6+rR169YQRotwUFBQoEceeUTp6enq6elRbW2tCgsL1d7eroiICHIQbsg777yjuLi4UUtfjNccRFEKmOAqKip07NixoPWAJAXNcZ85c6a8Xq/y8/PV09Oj6dOnWx0mwkxhYWFgOzs7W7m5uUpLS9OHH34op9MZwshwK2psbFRhYaFSU1MDbeQgAKFw4cIFrVixQsYYNTQ0BPVVV1cHtrOzs2W32/Xkk0/q5ZdflsPhsDpUhJHi4uLA9syZM5Wdna3p06dr//79ys/PD2FkuBVt27ZNpaWlio6ODmofrzmI6XvjRHJysiIiIka93erMmTPyeDwhigrhrrKyUnv27FFbW5vuuOOOMffNzc2VJHV3d1sRGm4xt912m+666y51d3fL4/Hor7/+0uDgYNA+5CNczalTp9TS0qInnnhizP3IQfgnV/LKWPdAHo9n1ItfLl68qHPnzpGXEHClIHXq1Cl9+eWXQU9JXU1ubq4uXryoH374wZoAccuYNm2akpOTA9cschCu11dffaWurq5r3hdJ4ycHUZQaJ+x2u3JyctTa2hpo8/v9am1tVV5eXggjQzgyxqiyslI7d+7Uvn37lJ6efs1jOjo6JEler/cmR4db0dDQkHp6euT1epWTk6OoqKigfNTV1aXTp0+TjzBKU1OTUlJS9PDDD4+5HzkI/yQ9PV0ejyco5/z22286dOhQIOfk5eVpcHBQhw8fDuyzb98++f3+QMETE9uVgtT333+vlpYWJSUlXfOYjo4OTZo0adS0LOCnn37SwMBA4JpFDsL1amxsVE5OjmbNmnXNfcdLDmL63jhSXV0tn8+nOXPmaO7cuXrttdc0PDys8vLyUIeGMFNRUaEdO3bok08+UVxcXGAue0JCgpxOp3p6erRjxw4tXrxYSUlJ6uzs1IYNG7RgwQJlZ2eHOHqEg40bN2rJkiVKS0tTb2+vNm3apIiICJWUlCghIUGrVq1SdXW1XC6X4uPjVVVVpby8PM2bNy/UoSOM+P1+NTU1yefzKTLyv7ck5CD83dDQUNBTcidPnlRHR4dcLpemTp2q9evXa8uWLZoxY4bS09NVV1en1NRULV26VJKUlZWlgoICrV69Wm+++aYuXLigyspKFRcXB00bxfg11jnk9Xq1fPlyfffdd9qzZ48uXboUuDdyuVyy2+1qb2/XoUOHtHDhQsXFxam9vV0bNmzQY489psTExFANCxYZ6/xxuVyqr69XUVGRPB6Penp69NxzzykjI0OLFi2SRA7Cta9j0uV/qDQ3N+uVV14Zdfy4zkGhfv0f/l2vv/66mTp1qrHb7Wbu3Lnm4MGDoQ4JYUjSVT9NTU3GGGNOnz5tFixYYFwul3E4HCYjI8M8++yz5tdffw1t4AgbK1euNF6v19jtdjNlyhSzcuVK093dHej/448/zLp160xiYqKJiYkxy5YtM319fSGMGOFo7969RpLp6uoKaicH4e/a2tquet3y+XzGGGP8fr+pq6szbrfbOBwOk5+fP+q8GhgYMCUlJWby5MkmPj7elJeXm/Pnz4dgNAiFsc6hkydP/uO9UVtbmzHGmMOHD5vc3FyTkJBgoqOjTVZWlnnppZfMyMhIaAcGS4x1/vz+++/moYceMrfffruJiooyaWlpZvXq1aa/vz/oN8hBE9u1rmPGGPPWW28Zp9NpBgcHRx0/nnOQzRhjbnrlCwAAAAAAAPgfrCkFAAAAAAAAy1GUAgAAAAAAgOUoSgEAAAAAAMByFKUAAAAAAABgOYpSAAAAAAAAsBxFKQAAAAAAAFiOohQAAAAAAAAsR1EKAAAAAAAAlqMoBQAAMMHYbDbt2rUr1GEAAIAJjqIUAACAhcrKymSz2UZ9CgoKQh0aAACApSJDHQAAAMBEU1BQoKampqA2h8MRomgAAABCgyelAAAALOZwOOTxeII+iYmJki5PrWtoaFBhYaGcTqemTZumjz76KOj4o0eP6sEHH5TT6VRSUpLWrFmjoaGhoH22bdume+65Rw6HQ16vV5WVlUH9Z8+e1bJlyxQTE6MZM2Zo9+7dN3fQAAAAf0NRCgAAIMzU1dWpqKhIR44cUWlpqYqLi3X8+HFJ0vDwsBYtWqTExER9++23am5uVktLS1DRqaGhQRUVFVqzZo2OHj2q3bt3KyMjI+hv1NfXa8WKFers7NTixYtVWlqqc+fOWTpOAAAwsdmMMSbUQQAAAEwUZWVlevfddxUdHR3UXltbq9raWtlsNq1du1YNDQ2Bvnnz5mn27Nl644039Pbbb6umpkY//vijYmNjJUmfffaZlixZot7eXrndbk2ZMkXl5eXasmXLVWOw2Wx64YUX9OKLL0q6XOiaPHmyPv/8c9a2AgAAlmFNKQAAAIstXLgwqOgkSS6XK7Cdl5cX1JeXl6eOjg5J0vHjxzVr1qxAQUqS5s+fL7/fr66uLtlsNvX29io/P3/MGLKzswPbsbGxio+P188///z/DgkAAOCGUZQCAACwWGxs7KjpdP8Wp9N5XftFRUUFfbfZbPL7/TcjJAAAgKtiTSkAAIAwc/DgwVHfs7KyJElZWVk6cuSIhoeHA/0HDhzQpEmTlJmZqbi4ON15551qbW21NGYAAIAbxZNSAAAAFvvzzz/V398f1BYZGank5GRJUnNzs+bMmaP7779f7733nr755hs1NjZKkkpLS7Vp0yb5fD5t3rxZv/zyi6qqqvT444/L7XZLkjZv3qy1a9cqJSVFhYWFOn/+vA4cOKCqqiprBwoAADAGilIAAAAW++KLL+T1eoPaMjMzdeLECUmX34z3wQcfaN26dfJ6vXr//fd19913S5JiYmK0d+9ePfPMM7rvvvsUExOjoqIibd26NfBbPp9PIyMjevXVV7Vx40YlJydr+fLl1g0QAADgOvD2PQAAgDBis9m0c+dOLV26NNShAAAA3FSsKQUAAAAAAADLUZQCAAAAAACA5VhTCgAAIIywsgIAAJgoeFIKAAAAAAAAlqMoBQAAAAAAAMtRlAIAAAAAAIDlKEoBAAAAAADAchSlAAAAAAAAYDmKUgAAAAAAALAcRSkAAAAAAABYjqIUAAAAAAAALEdRCgAAAAAAAJb7D+qgn69WaQwUAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from logging import NullHandler\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize empty lists\n",
        "epochs = []\n",
        "valid_accuracies = []\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "separate_loss = []\n",
        "lang_loss = []\n",
        "\n",
        "# Read and parse the log file\n",
        "with open('/content/results/convtasnet/1234/train_log.txt', 'r') as file:\n",
        "  epoch_match = None\n",
        "  train_loss_match = None\n",
        "  valid_loss_match = None\n",
        "  for line in file:\n",
        "      # Use regular expressions to extract values\n",
        "      if(epoch_match == None):\n",
        "        epoch_match = re.search(r'epoch: (\\d+)', line)\n",
        "      # acc_match = re.search(r'Valid Accuracy: ([\\deE\\+\\-\\.]+)', line)\n",
        "      if(train_loss_match == None):\n",
        "        train_loss_match = re.search(r'train final_loss: ([\\deE\\+\\-\\.]+)', line)\n",
        "      if(valid_loss_match == None):\n",
        "        valid_loss_match = re.search(r'valid final_loss: ([\\deE\\+\\-\\.]+)', line)\n",
        "      # print(valid_loss_match)\n",
        "      # separate_loss_match = re.search(r'valid separate_loss: ([\\deE\\+\\-\\.]+)', line)\n",
        "      # lang_loss_match = re.search(r'valid lang_loss: ([\\deE\\+\\-\\.]+)', line)\n",
        "\n",
        "      if epoch_match and train_loss_match and valid_loss_match :\n",
        "          epochs.append(int(epoch_match.group(1)))\n",
        "          # valid_accuracies.append(float(acc_match.group(1)))\n",
        "          train_losses.append(float(train_loss_match.group(1)))\n",
        "          valid_losses.append(float(valid_loss_match.group(1)))\n",
        "          epoch_match = None\n",
        "          train_loss_match = None\n",
        "          valid_loss_match = None\n",
        "\n",
        "print(train_losses)\n",
        "print(valid_losses)\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.plot(epochs, valid_accuracies, marker='o', label='Valid Accuracy', color='green')\n",
        "# plt.title(\"Epoch vs Valid Accuracy\")\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.grid(True)\n",
        "# plt.legend()\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_losses, marker='o', label='Train Loss', color='blue')\n",
        "plt.plot(epochs, valid_losses, marker='o', label='Valid Loss', color='orange')\n",
        "# plt.plot(epochs, separate_loss, marker='o', label='Separate Loss', color='red')\n",
        "# plt.plot(epochs, lang_loss, marker='o', label='Lang Loss', color='purple')\n",
        "plt.title(\"Epoch vs Final Losses\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EbZRnqoLHN2"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqunrgl_LIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff54438-f84c-4aad-8630-5aabddabf4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [01:07<00:00, 11.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - Epoch loaded: 176, Accuracy soft: 4.36e-02, Accuracy Partial: 1.14e-01 - test final_loss: -3.25e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3.2517144298047014"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Eval\n",
        "separator.evaluate( test_data, min_key=\"si-snr\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fDlVO7X7pbgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5DXWBB4nE47"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "separator.save_results(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhv8AFvfH3GF"
      },
      "source": [
        "End Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dotxyi4D42F"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/results\n",
        "# !cp -r /content/results /content/drive/MyDrive/Project/\n",
        "# !cp -r /content/hparams/conVasNet.yml /content/drive/MyDrive/Project/results/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLCcz960OCEr"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZg-Wj6sh6fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTLbay6jCm-g"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import os\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.manifold import TSNE\n",
        "\n",
        "# all_embeddings = []\n",
        "# all_labels = []\n",
        "# all_epochs = []\n",
        "\n",
        "# # Folder where your .pt files are stored\n",
        "# embedding_dir = \"/content/\"  # Change to your path\n",
        "\n",
        "# # Load all epoch files\n",
        "# for epoch in range(1, 12):\n",
        "#     file_path = os.path.join(embedding_dir, f\"embeddings_epoch{epoch}.pt\")\n",
        "\n",
        "#     emb = torch.load(file_path)\n",
        "#     embeddings = emb[\"embeddings\"].squeeze(1)  # from [N, 1, D] → [N, D]\n",
        "#     labels = emb[\"labels\"]  # assumes each file has (embeddings, lang_id)\n",
        "\n",
        "#     all_embeddings.append(embeddings)\n",
        "#     all_labels.append(labels)\n",
        "#     all_epochs.append(torch.full((embeddings.size(0),), epoch))\n",
        "\n",
        "# # Concatenate everything\n",
        "# all_embeddings = torch.cat(all_embeddings, dim=0)\n",
        "# all_labels = torch.cat(all_labels, dim=0)\n",
        "# all_epochs = torch.cat(all_epochs, dim=0)\n",
        "\n",
        "# # Run t-SNE\n",
        "# tsne = TSNE(n_components=2, random_state=42)\n",
        "# reduced_emb = tsne.fit_transform(all_embeddings.numpy())\n",
        "\n",
        "# # Plot\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# sns.scatterplot(x=reduced_emb[:, 0], y=reduced_emb[:, 1], hue=all_epochs.numpy(), palette=\"viridis\", s=10)\n",
        "# plt.title(\"t-SNE of Embeddings Over Epochs\")\n",
        "# plt.xlabel(\"TSNE-1\")\n",
        "# plt.ylabel(\"TSNE-2\")\n",
        "# plt.legend(title=\"Epoch\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# plt.tight_layout()\n",
        "# plt.grid(True)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9iOhxM7dHxb"
      },
      "outputs": [],
      "source": [
        "!cp /content/hparams/conVasNet_p.yml /content/drive/MyDrive/Project"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}